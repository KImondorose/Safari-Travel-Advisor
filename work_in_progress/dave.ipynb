{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://www.lonelyplanet.com/kenya/attractions'\n",
    "# response = requests.get(url)\n",
    "# soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attaractions = soup.find_all('span', class_ ='heading-05 font-semibold')\n",
    "# for attraction in attaractions:\n",
    "#     title = attraction.get_text(strip=True)\n",
    "#     print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_url = 'https://www.lonelyplanet.com/kenya/attractions'\n",
    "\n",
    "# # pages\n",
    "# num_pages = 5 \n",
    "\n",
    "# # Loop through each page\n",
    "# for page in range(1, num_pages + 1):\n",
    "#     # Constructing the URL for each page\n",
    "#     url = f'{base_url}?page={page}'\n",
    "#     response = requests.get(url)\n",
    "#     soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "#     # Find all span elements with the class 'heading-05 font-semibold'\n",
    "#     attractions = soup.find_all('span', class_='heading-05 font-semibold')\n",
    "    \n",
    "#     # Print each attraction title\n",
    "#     for attraction in attractions:\n",
    "#         title = attraction.get_text(strip=True)\n",
    "#         print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "\n",
    "# # Function to scrape a single country's attractions\n",
    "# def scrape_country_attractions(country, continent, base_url, num_pages=5):\n",
    "#     data = []  # List to store all attraction data for the country\n",
    "\n",
    "#     for page in range(1, num_pages + 1):\n",
    "#         url = f'{base_url}?page={page}'\n",
    "#         response = requests.get(url)\n",
    "#         soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "#         # Extract attraction titles and descriptions\n",
    "#         titles = soup.find_all('span', class_='heading-05 font-semibold')\n",
    "#         descriptions = soup.find_all('p', class_='relative line-clamp-3')\n",
    "\n",
    "#         # Pair up each title with its corresponding description and add country/continent info\n",
    "#         for title, description in zip(titles, descriptions):\n",
    "#             data.append({\n",
    "#                 'Attraction': title.get_text(strip=True),\n",
    "#                 'Description': description.get_text(strip=True),\n",
    "#                 'Country': country,\n",
    "#                 'Continent': continent\n",
    "#             })\n",
    "\n",
    "#     return data\n",
    "\n",
    "# # Define the countries, continents, and base URLs you want to scrape\n",
    "# countries_to_scrape = [\n",
    "#     {'country': 'Kenya', 'continent': 'Africa', 'url': 'https://www.lonelyplanet.com/kenya/attractions'},\n",
    "    \n",
    "# ]\n",
    "\n",
    "# # Collect data for all countries\n",
    "# all_data = []\n",
    "# for entry in countries_to_scrape:\n",
    "#     country_data = scrape_country_attractions(entry['country'], entry['continent'], entry['url'])\n",
    "#     all_data.extend(country_data)\n",
    "\n",
    "# # Convert to DataFrame and save to CSV\n",
    "# df = pd.DataFrame(all_data, columns=['Attraction', 'Description', 'Country', 'Continent'])\n",
    "# df.to_csv('attractions_data.csv', index=False)\n",
    "# print(\"Data saved to attractions_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_to_scrape = [\n",
    "    # Africa\n",
    "    {'country': 'Kenya', 'continent': 'Africa', 'url': 'https://www.lonelyplanet.com/kenya/attractions'},\n",
    "    {'country': 'South Africa', 'continent': 'Africa', 'url': 'https://www.lonelyplanet.com/south-africa/attractions'},\n",
    "    {'country': 'Egypt', 'continent': 'Africa', 'url': 'https://www.lonelyplanet.com/egypt/attractions'},\n",
    "    {'country': 'Morocco', 'continent': 'Africa', 'url': 'https://www.lonelyplanet.com/morocco/attractions'},\n",
    "\n",
    "    # Asia\n",
    "    {'country': 'Japan', 'continent': 'Asia', 'url': 'https://www.lonelyplanet.com/japan/attractions'},\n",
    "    {'country': 'China', 'continent': 'Asia', 'url': 'https://www.lonelyplanet.com/china/attractions'},\n",
    "    {'country': 'India', 'continent': 'Asia', 'url': 'https://www.lonelyplanet.com/india/attractions'},\n",
    "    {'country': 'Thailand', 'continent': 'Asia', 'url': 'https://www.lonelyplanet.com/thailand/attractions'},\n",
    "\n",
    "    # Europe\n",
    "    {'country': 'France', 'continent': 'Europe', 'url': 'https://www.lonelyplanet.com/france/attractions'},\n",
    "    {'country': 'Italy', 'continent': 'Europe', 'url': 'https://www.lonelyplanet.com/italy/attractions'},\n",
    "    {'country': 'Germany', 'continent': 'Europe', 'url': 'https://www.lonelyplanet.com/germany/attractions'},\n",
    "    {'country': 'United Kingdom', 'continent': 'Europe', 'url': 'https://www.lonelyplanet.com/united-kingdom/attractions'},\n",
    "\n",
    "    # North America\n",
    "    {'country': 'United States', 'continent': 'North America', 'url': 'https://www.lonelyplanet.com/usa/attractions'},\n",
    "    {'country': 'Canada', 'continent': 'North America', 'url': 'https://www.lonelyplanet.com/canada/attractions'},\n",
    "    {'country': 'Mexico', 'continent': 'North America', 'url': 'https://www.lonelyplanet.com/mexico/attractions'},\n",
    "\n",
    "    # South America\n",
    "    {'country': 'Brazil', 'continent': 'South America', 'url': 'https://www.lonelyplanet.com/brazil/attractions'},\n",
    "    {'country': 'Argentina', 'continent': 'South America', 'url': 'https://www.lonelyplanet.com/argentina/attractions'},\n",
    "    {'country': 'Chile', 'continent': 'South America', 'url': 'https://www.lonelyplanet.com/chile/attractions'},\n",
    "    {'country': 'Peru', 'continent': 'South America', 'url': 'https://www.lonelyplanet.com/peru/attractions'},\n",
    "\n",
    "    # Oceania\n",
    "    {'country': 'Australia', 'continent': 'Oceania', 'url': 'https://www.lonelyplanet.com/australia/attractions'},\n",
    "    {'country': 'New Zealand', 'continent': 'Oceania', 'url': 'https://www.lonelyplanet.com/new-zealand/attractions'},\n",
    "    {'country': 'Fiji', 'continent': 'Oceania', 'url': 'https://www.lonelyplanet.com/fiji/attractions'},\n",
    "\n",
    "    # Middle East\n",
    "    {'country': 'United Arab Emirates', 'continent': 'Middle East', 'url': 'https://www.lonelyplanet.com/united-arab-emirates/attractions'},\n",
    "    {'country': 'Turkey', 'continent': 'Middle East', 'url': 'https://www.lonelyplanet.com/turkey/attractions'},\n",
    "    {'country': 'Israel', 'continent': 'Middle East', 'url': 'https://www.lonelyplanet.com/israel/attractions'},\n",
    "    {'country': 'Jordan', 'continent': 'Middle East', 'url': 'https://www.lonelyplanet.com/jordan/attractions'},\n",
    "\n",
    "    # Antarctica (if applicable)\n",
    "    {'country': 'Antarctica', 'continent': 'Antarctica', 'url': 'https://www.lonelyplanet.com/antarctica/attractions'}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "\n",
    "# def scrape_country_attractions(country, continent, base_url, num_pages=5):\n",
    "#     data = []\n",
    "#     for page in range(1, num_pages + 1):\n",
    "#         url = f'{base_url}?page={page}'\n",
    "#         response = requests.get(url)\n",
    "#         soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "#         titles = soup.find_all('span', class_='heading-05 font-semibold')\n",
    "#         descriptions = soup.find_all('p', class_='relative line-clamp-3')\n",
    "\n",
    "#         for title, description in zip(titles, descriptions):\n",
    "#             data.append({\n",
    "#                 'Attraction': title.get_text(strip=True),\n",
    "#                 'Description': description.get_text(strip=True),\n",
    "#                 'Country': country,\n",
    "#                 'Continent': continent\n",
    "#             })\n",
    "#     return data\n",
    "\n",
    "# all_data = []\n",
    "# for entry in countries_to_scrape:\n",
    "#     country_data = scrape_country_attractions(entry['country'], entry['continent'], entry['url'])\n",
    "#     all_data.extend(country_data)\n",
    "\n",
    "# df = pd.DataFrame(all_data, columns=['Attraction', 'Description', 'Country', 'Continent'])\n",
    "# df.to_csv('attractions_data.csv', index=False)\n",
    "# print(\"Data saved to attractions_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
