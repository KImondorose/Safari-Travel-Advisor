{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION, PROBLEM STATEMENT, AND BUSINESS UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Traveling is one of the most cherished experiences globally, but finding the perfect destination that aligns with individual preferences, interests, or vacation goals remains a significant challenge for many. Travelers often spend hours researching potential destinations, sifting through reviews, or consulting friends and family to decide where to go. However, this process can be overwhelming due to the abundance of information available online, coupled with the difficulty of aligning their unique interests with the offerings of different destinations.\n",
    "\n",
    "This project aims to solve this problem by leveraging machine learning to suggest and predict personalized travel destinations based on users' interests or the activities they wish to engage in during their vacations. By analyzing destination characteristics, the model can provide tailored suggestions, saving users time and effort while increasing their satisfaction with travel planning.\n",
    "\n",
    "### Stakeholders:\n",
    "\n",
    "- Travel Enthusiasts: Individuals seeking new destinations that align with their personal interests (e.g., art lovers wanting to visit galleries, nature enthusiasts looking for scenic hikes).\n",
    "- Travel Agencies and Platforms: Businesses like Expedia, Booking.com, or TripAdvisor, which can integrate this  system to enhance their customer experience and increase user engagement.\n",
    "- Destination Marketers: Local tourism boards or global travel organizations that can use the model to promote destinations based on specific target audience preferences.\n",
    "\n",
    "These stakeholders would use the model to simplify decision-making, enhance customer experiences, and drive engagement or revenue growth by promoting destinations aligned with user interests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Travel planning involves a complex interplay of preferences, budgets, and activities, often leaving individuals overwhelmed by choices or dissatisfied with their final decisions. For example, someone interested in art galleries might unknowingly miss an underrated artistic hub. Similarly, adventure seekers might struggle to identify destinations with off-the-beaten-path hiking opportunities due to limited information.\n",
    "\n",
    "**Real-World Problem**: The real-world problem is the gap between the vast number of global travel destinations and the ability of travelers to identify those that best align with their personal interests and activities. This misalignment leads to dissatisfaction, wasted time, and potentially missed opportunities for both travelers and businesses.\n",
    "\n",
    "**Value Proposition**: This project addresses these challenges by providing a system that:\n",
    "\n",
    "- For Travelers: Reduces decision fatigue by offering personalized suggestions tailored to their unique interests.\n",
    "- For Travel Businesses: Increases user engagement, loyalty, and potential upselling opportunities by curating destinations that resonate with users.\n",
    "- For Destination Marketers: Enables targeted marketing campaigns, focusing on promoting destinations to the most relevant audiences.\n",
    "\n",
    "By solving this problem, the project creates a win-win scenario for travelers seeking memorable experiences and businesses aiming to enhance their service offerings and revenue streams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBJECTIVES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary objective of this project is:\n",
    "\n",
    "- To create a machine learning model that can interpret user preferences and predict suitable country destinations using text classification techniques.\n",
    "\n",
    "The secondary objectives are:\n",
    "- To analyze the common descriptors used for top destinations on travel websites, using Lonely Planet's sample data as a benchmark.\n",
    "- To compare attraction distribution across countries to identify imbalances, using Lonely Planet's sample data as a benchmark.\n",
    "- To determine which countries are overrepresented on travel websites.\n",
    "- To analyze international travel websites' marketing of Kenyan destinations and identify popular attractions and descriptive language used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The success of this machine learning model hinges on the quality and relevance of the dataset, as it directly impacts the ability to provide accurate and meaningful suggestions. For this project, data was scraped from Lonely Planet's website, focusing on their curated list of must-see attractions across 25 countries. For example, [U.S. top attractions](https://www.lonelyplanet.com/usa/attractions). The dataset is well-suited to addressing the business problem because it encapsulates rich descriptive information about attractions, which is directly aligned with the model's goal of predicting the most relevant destination based on user interests.\n",
    "Here is the [Python File](https://github.com/KImondorose/Travel-WordFinder/blob/main/Scraping_Python_File/lonely_planet_scraper.py) showing the scraping process.\n",
    "\n",
    "## 1. Dataset Size\n",
    "The scraped dataset contains:\n",
    "\n",
    "18,040 rows, representing 18,040 unique text descriptions of must-see attractions across 25 countries.\n",
    "This dataset size is sufficient for training a machine learning model to generalize well while covering a diverse range of attractions.\n",
    "Each row corresponds to a single attraction, and the dataset offers both breadth and depth, with numerous attractions for each country. This enables the model to learn the nuanced differences in attraction types and their associations with specific destinations.\n",
    "\n",
    "## 2. Data Sources and Suitability\n",
    "The dataset includes information about the must-see attractions in each of the 25 countries, which was scraped from a reputable travel platform, Lonely Planet. Lonely Planet is a trusted resource in the travel industry, known for its in-depth and authentic coverage of global destinations. This ensures that the dataset is both reliable and relevant for a model designed to suggest/recommend travel destinations.\n",
    "\n",
    "**Key features of the data include:**\n",
    "- Description (Feature): The primary input for the model, offering detailed linguistic cues about each attraction.\n",
    "- Country (Target): The output of the model, representing the predicted destination for a user’s input.\n",
    "- Attraction Name: Contextual information included but not used directly in the model.\n",
    "The description feature allows the model to capture user preferences and connect them to relevant destinations, while the country serves as the interpretable classification target.\n",
    "The attraction descriptions serve as the core feature for the model, as they encapsulate the essence of what travelers may be seeking (e.g., cultural landmarks, artistic experiences, natural beauty). This aligns with the business problem of connecting user inputs (e.g., \"art galleries\" or \"hiking trails\") to potential destinations.\n",
    "\n",
    "\n",
    "## 3. Utility for the Real-World Problem\n",
    "The dataset is diverse and granular, with 18,040 unique attraction descriptions across 25 countries. Its richness and alignment with user interests make it suitable for creating a system that predicts destinations based on minimal user input. The data enables the model to generalize across a wide range of preferences, effectively addressing the challenge of personalized travel suggestions/recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the dataset provides a solid foundation for a destination prediction system, several limitations could impact the model's performance and generalizability:\n",
    "\n",
    "- Imbalanced Dataset: Some countries have significantly more attractions than others, potentially biasing the model toward over-represented countries. To address this, techniques like oversampling (e.g., SMOTE) or undersampling will be applied, and evaluation metrics like F1-score will ensure fair assessment across classes.\n",
    "\n",
    "- Non-English Text: Some descriptions contain non-English words, which may introduce noise as the primary target language is English. This will be handled by translating non-English text where feasible or filtering it out during preprocessing.\n",
    "\n",
    "- Text Cleaning: Raw text often includes irrelevant characters, stopwords, or inconsistencies. Cleaning will involve removing punctuation, stopwords, and applying lemmatization to standardize and refine the input data.\n",
    "\n",
    "- Limited Geographic Scope: The dataset covers only 25 countries, limiting global applicability. Future iterations can incorporate additional data from other platforms or regions to expand coverage, with potential use of transfer learning to adapt the model to new data.\n",
    "\n",
    "- By addressing these challenges through targeted preprocessing and robust modeling strategies, the project aims to ensure accurate and scalable predictions while laying the groundwork for future enhancements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import string\n",
    "import regex as re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "from nltk import FreqDist\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score, accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn import set_config\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud\n",
    "from textwrap import wrap\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOADING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load the dataset as obtained through the scraping process which can be accessed in this [python file](https://github.com/KImondorose/Travel-WordFinder/tree/main/Scraping_Python_File)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attraction</th>\n",
       "      <th>Description</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amboseli National Park</td>\n",
       "      <td>Amboseli belongs in the elite of Kenya’s natio...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fort Jesus</td>\n",
       "      <td>This 16th-century fort and Unesco World Herita...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Sheldrick Wildlife Trust</td>\n",
       "      <td>Occupying a plot within Nairobi National Park,...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nairobi National Park</td>\n",
       "      <td>Welcome to Kenya’s most accessible yet incongr...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>National Museum</td>\n",
       "      <td>Kenya’s wonderful National Museum, housed in a...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Attraction  \\\n",
       "0          Amboseli National Park   \n",
       "1                      Fort Jesus   \n",
       "2  David Sheldrick Wildlife Trust   \n",
       "3           Nairobi National Park   \n",
       "4                 National Museum   \n",
       "\n",
       "                                         Description Country Continent  \n",
       "0  Amboseli belongs in the elite of Kenya’s natio...   Kenya    Africa  \n",
       "1  This 16th-century fort and Unesco World Herita...   Kenya    Africa  \n",
       "2  Occupying a plot within Nairobi National Park,...   Kenya    Africa  \n",
       "3  Welcome to Kenya’s most accessible yet incongr...   Kenya    Africa  \n",
       "4  Kenya’s wonderful National Museum, housed in a...   Kenya    Africa  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/rosew/Desktop/Moringa/phase_5/Travel-WordFinder/Data/best_travel_destinations_for_2025.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORE/CLEAN THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18040 entries, 0 to 18039\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Attraction   18040 non-null  object\n",
      " 1   Description  18040 non-null  object\n",
      " 2   Country      18040 non-null  object\n",
      " 3   Continent    18040 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 563.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df. info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 18,040 columns and 4 columns (Attraction, Description, Country, and Continent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attraction</th>\n",
       "      <th>Description</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18040</td>\n",
       "      <td>18040</td>\n",
       "      <td>18040</td>\n",
       "      <td>18040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>17185</td>\n",
       "      <td>18024</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Cathedral</td>\n",
       "      <td>Buddhist ruins in Si Satchanalai-Chaliang Hist...</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>1200</td>\n",
       "      <td>4480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Attraction                                        Description Country  \\\n",
       "count       18040                                              18040   18040   \n",
       "unique      17185                                              18024      25   \n",
       "top     Cathedral  Buddhist ruins in Si Satchanalai-Chaliang Hist...  Canada   \n",
       "freq           19                                                  4    1200   \n",
       "\n",
       "       Continent  \n",
       "count      18040  \n",
       "unique         7  \n",
       "top         Asia  \n",
       "freq        4480  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18040, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df. shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attraction     0\n",
       "Description    0\n",
       "Country        0\n",
       "Continent      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No null values because we scraped everything ourselves. Just to double-check:\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Attraction  \\\n",
      "3439                              Yuexiu Park   \n",
      "3440                              Yuexiu Park   \n",
      "3479   Palace of Moon & Water Kwun Yum Temple   \n",
      "3480   Palace of Moon & Water Kwun Yum Temple   \n",
      "3639                       Rakadrak Hermitage   \n",
      "3640                       Rakadrak Hermitage   \n",
      "3679                          Huilan Pavilion   \n",
      "3680                          Huilan Pavilion   \n",
      "4999                         Pithoragarh Fort   \n",
      "5000                         Pithoragarh Fort   \n",
      "5157                    Himadri Hans Handloom   \n",
      "5160                    Himadri Hans Handloom   \n",
      "11559                             Kids Market   \n",
      "11560                             Kids Market   \n",
      "11637        Africville Heritage Trust Museum   \n",
      "11641        Africville Heritage Trust Museum   \n",
      "14359                       Cementerios 1 & 2   \n",
      "14360                       Cementerios 1 & 2   \n",
      "\n",
      "                                             Description Country  \\\n",
      "3439   A crenellated roadway between attractions in t...   China   \n",
      "3440   A crenellated roadway between attractions in t...   China   \n",
      "3479   Not to be confused with Kwun Yum Temple nearby...   China   \n",
      "3480   Not to be confused with Kwun Yum Temple nearby...   China   \n",
      "3639   This hermitage high above Lhasa has three simp...   China   \n",
      "3640   This hermitage high above Lhasa has three simp...   China   \n",
      "3679   Lit up at night, this graceful pavilion decora...   China   \n",
      "3680   Lit up at night, this graceful pavilion decora...   China   \n",
      "4999   This renovated historic fort was built by Gurk...   India   \n",
      "5000   This renovated historic fort was built by Gurk...   India   \n",
      "5157   Just north of town on the road to Binsar is th...   India   \n",
      "5160   Just north of town on the road to Binsar is th...   India   \n",
      "11559  A kaleidoscopic mini shopping mall for under-1...  Canada   \n",
      "11560  A kaleidoscopic mini shopping mall for under-1...  Canada   \n",
      "11637  Learn the story of Africville, Halifax's predo...  Canada   \n",
      "11641  Learn the story of Africville, Halifax's predo...  Canada   \n",
      "14359  The city's most illustrious, influential and i...   Chile   \n",
      "14360  The city's most illustrious, influential and i...   Chile   \n",
      "\n",
      "           Continent  \n",
      "3439            Asia  \n",
      "3440            Asia  \n",
      "3479            Asia  \n",
      "3480            Asia  \n",
      "3639            Asia  \n",
      "3640            Asia  \n",
      "3679            Asia  \n",
      "3680            Asia  \n",
      "4999            Asia  \n",
      "5000            Asia  \n",
      "5157            Asia  \n",
      "5160            Asia  \n",
      "11559  North America  \n",
      "11560  North America  \n",
      "11637  North America  \n",
      "11641  North America  \n",
      "14359  South America  \n",
      "14360  South America  \n"
     ]
    }
   ],
   "source": [
    "all_duplicates = df[df.duplicated(keep=False)]\n",
    "print(all_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The duplicated attraction is Grimspound in England. Since it contains the same exact attraction, we can drop it from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Attraction, Description, Country, Continent]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "all_duplicates = df[df.duplicated(keep=False)]\n",
    "print(all_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('/Users/rosew/Downloads/best_travel_destinations_for_2025_df_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Kenya', 'South Africa', 'Egypt', 'Morocco', 'Japan', 'China',\n",
       "       'India', 'Thailand', 'France', 'Italy', 'Germany', 'United States',\n",
       "       'Canada', 'Mexico', 'Brazil', 'Argentina', 'Chile', 'Peru',\n",
       "       'Australia', 'New Zealand', 'Fiji', 'United Arab Emirates',\n",
       "       'Turkey', 'Israel', 'Jordan'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique Countries: 25\n"
     ]
    }
   ],
   "source": [
    "display(df.Country.unique())\n",
    "print('Total Unique Countries:', len(df.Country.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "Germany                 0.066552\n",
       "France                  0.066552\n",
       "Australia               0.066552\n",
       "United States           0.066552\n",
       "Japan                   0.066552\n",
       "Italy                   0.066552\n",
       "Canada                  0.066441\n",
       "India                   0.066441\n",
       "China                   0.066330\n",
       "Mexico                  0.059897\n",
       "Turkey                  0.057678\n",
       "Thailand                0.048805\n",
       "South Africa            0.035494\n",
       "Brazil                  0.033276\n",
       "Egypt                   0.028839\n",
       "New Zealand             0.022184\n",
       "Morocco                 0.019966\n",
       "Argentina               0.019966\n",
       "Peru                    0.019966\n",
       "Chile                   0.017692\n",
       "Israel                  0.008874\n",
       "Kenya                   0.008874\n",
       "Jordan                  0.008874\n",
       "United Arab Emirates    0.006655\n",
       "Fiji                    0.004437\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Country.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = df.groupby('Country').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "countries.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Attraction</th>\n",
       "      <th>Description</th>\n",
       "      <th>Continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Italy</td>\n",
       "      <td>1200</td>\n",
       "      <td>1200</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>France</td>\n",
       "      <td>1200</td>\n",
       "      <td>1200</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Japan</td>\n",
       "      <td>1200</td>\n",
       "      <td>1200</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>1200</td>\n",
       "      <td>1200</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Germany</td>\n",
       "      <td>1200</td>\n",
       "      <td>1200</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>United States</td>\n",
       "      <td>1200</td>\n",
       "      <td>1200</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>India</td>\n",
       "      <td>1198</td>\n",
       "      <td>1198</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canada</td>\n",
       "      <td>1198</td>\n",
       "      <td>1198</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>China</td>\n",
       "      <td>1196</td>\n",
       "      <td>1196</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>1040</td>\n",
       "      <td>1040</td>\n",
       "      <td>1040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>880</td>\n",
       "      <td>880</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>520</td>\n",
       "      <td>520</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Peru</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Morocco</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chile</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Jordan</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Israel</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fiji</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Country  Attraction  Description  Continent\n",
       "12                 Italy        1200         1200       1200\n",
       "8                 France        1200         1200       1200\n",
       "13                 Japan        1200         1200       1200\n",
       "1              Australia        1200         1200       1200\n",
       "9                Germany        1200         1200       1200\n",
       "24         United States        1200         1200       1200\n",
       "10                 India        1198         1198       1198\n",
       "3                 Canada        1198         1198       1198\n",
       "5                  China        1196         1196       1196\n",
       "16                Mexico        1080         1080       1080\n",
       "22                Turkey        1040         1040       1040\n",
       "21              Thailand         880          880        880\n",
       "20          South Africa         640          640        640\n",
       "2                 Brazil         600          600        600\n",
       "6                  Egypt         520          520        520\n",
       "18           New Zealand         400          400        400\n",
       "19                  Peru         360          360        360\n",
       "0              Argentina         360          360        360\n",
       "17               Morocco         360          360        360\n",
       "4                  Chile         319          319        319\n",
       "14                Jordan         160          160        160\n",
       "11                Israel         160          160        160\n",
       "15                 Kenya         160          160        160\n",
       "23  United Arab Emirates         120          120        120\n",
       "7                   Fiji          80           80         80"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_countries = countries.sort_values(by='Attraction', ascending=False)\n",
    "sorted_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the class imbalance\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.barplot(x='Attraction', y='Country', data=sorted_countries, palette='icefire')\n",
    "plt.title('Attractions Per Country')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This will likely be an issue when modeling, so we will try to use class weights to fix this problem**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT CLEANING, PREPROCESSING, AND FURTHER EXPLORATION\n",
    "- Removing punctuation and numbers\n",
    "- Lowercasing everything\n",
    "- Removing stopwords\n",
    "- Creating a document term matrix grouped by Country\n",
    "  - Count Vectorization\n",
    "  - TF-IDF Vectorization\n",
    "  - Bi-grams\n",
    "- Creating a document term matrix grouped by Continent\n",
    "  - Count Vectorization\n",
    "  - TF-IDF Vectorization\n",
    "  - Bi-grams\n",
    "- Visualize most frequent words\n",
    "  - Word clouds\n",
    "  - Bar plot or histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of stop words\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list+= list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the list\n",
    "stopwords_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save stopwords list for app\n",
    "# joblib.dump(stopwords_list, '/Users/tiaplagata/Documents/Flatiron/capstone-project/Data/stopwords_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attraction</th>\n",
       "      <th>Description</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amboseli National Park</td>\n",
       "      <td>Amboseli belongs in the elite of Kenya’s natio...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>amboseli belongs in the elite of kenya’s natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fort Jesus</td>\n",
       "      <td>This 16th-century fort and Unesco World Herita...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>this 16th-century fort and unesco world herita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Sheldrick Wildlife Trust</td>\n",
       "      <td>Occupying a plot within Nairobi National Park,...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>occupying a plot within nairobi national park,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nairobi National Park</td>\n",
       "      <td>Welcome to Kenya’s most accessible yet incongr...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>welcome to kenya’s most accessible yet incongr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>National Museum</td>\n",
       "      <td>Kenya’s wonderful National Museum, housed in a...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>kenya’s wonderful national museum, housed in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18035</th>\n",
       "      <td>Byzantine Basilica</td>\n",
       "      <td>Near the Citadel's archaeological museum is th...</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>near the citadel's archaeological museum is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18036</th>\n",
       "      <td>Sharif Al Hussein Bin Ali Mosque</td>\n",
       "      <td>This grand and beautiful gleaming white mosque...</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>this grand and beautiful gleaming white mosque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18037</th>\n",
       "      <td>North Theatre</td>\n",
       "      <td>The North Theatre is overgrown and missing muc...</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>the north theatre is overgrown and missing muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18038</th>\n",
       "      <td>Shops</td>\n",
       "      <td>The shells of a row of shops remain in the wes...</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>the shells of a row of shops remain in the wes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18039</th>\n",
       "      <td>Rakhabat Canyon</td>\n",
       "      <td>Close to Rum village, the labyrinthine siqs of...</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>close to rum village, the labyrinthine siqs of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18031 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Attraction  \\\n",
       "0                Amboseli National Park   \n",
       "1                            Fort Jesus   \n",
       "2        David Sheldrick Wildlife Trust   \n",
       "3                 Nairobi National Park   \n",
       "4                       National Museum   \n",
       "...                                 ...   \n",
       "18035                Byzantine Basilica   \n",
       "18036  Sharif Al Hussein Bin Ali Mosque   \n",
       "18037                     North Theatre   \n",
       "18038                             Shops   \n",
       "18039                   Rakhabat Canyon   \n",
       "\n",
       "                                             Description Country    Continent  \\\n",
       "0      Amboseli belongs in the elite of Kenya’s natio...   Kenya       Africa   \n",
       "1      This 16th-century fort and Unesco World Herita...   Kenya       Africa   \n",
       "2      Occupying a plot within Nairobi National Park,...   Kenya       Africa   \n",
       "3      Welcome to Kenya’s most accessible yet incongr...   Kenya       Africa   \n",
       "4      Kenya’s wonderful National Museum, housed in a...   Kenya       Africa   \n",
       "...                                                  ...     ...          ...   \n",
       "18035  Near the Citadel's archaeological museum is th...  Jordan  Middle East   \n",
       "18036  This grand and beautiful gleaming white mosque...  Jordan  Middle East   \n",
       "18037  The North Theatre is overgrown and missing muc...  Jordan  Middle East   \n",
       "18038  The shells of a row of shops remain in the wes...  Jordan  Middle East   \n",
       "18039  Close to Rum village, the labyrinthine siqs of...  Jordan  Middle East   \n",
       "\n",
       "                                                 Cleaned  \n",
       "0      amboseli belongs in the elite of kenya’s natio...  \n",
       "1      this 16th-century fort and unesco world herita...  \n",
       "2      occupying a plot within nairobi national park,...  \n",
       "3      welcome to kenya’s most accessible yet incongr...  \n",
       "4      kenya’s wonderful national museum, housed in a...  \n",
       "...                                                  ...  \n",
       "18035  near the citadel's archaeological museum is th...  \n",
       "18036  this grand and beautiful gleaming white mosque...  \n",
       "18037  the north theatre is overgrown and missing muc...  \n",
       "18038  the shells of a row of shops remain in the wes...  \n",
       "18039  close to rum village, the labyrinthine siqs of...  \n",
       "\n",
       "[18031 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowercase all words in each corpus\n",
    "df_to_clean = df.copy()\n",
    "df_to_clean['Cleaned'] = df_to_clean['Description'].apply(lambda x: x.lower())\n",
    "df_to_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attraction</th>\n",
       "      <th>Description</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amboseli National Park</td>\n",
       "      <td>Amboseli belongs in the elite of Kenya’s natio...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>amboseli belongs in the elite of kenya’s natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fort Jesus</td>\n",
       "      <td>This 16th-century fort and Unesco World Herita...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>this 16thcentury fort and unesco world heritag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Sheldrick Wildlife Trust</td>\n",
       "      <td>Occupying a plot within Nairobi National Park,...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>occupying a plot within nairobi national park ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nairobi National Park</td>\n",
       "      <td>Welcome to Kenya’s most accessible yet incongr...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>welcome to kenya’s most accessible yet incongr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>National Museum</td>\n",
       "      <td>Kenya’s wonderful National Museum, housed in a...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>kenya’s wonderful national museum housed in an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Attraction  \\\n",
       "0          Amboseli National Park   \n",
       "1                      Fort Jesus   \n",
       "2  David Sheldrick Wildlife Trust   \n",
       "3           Nairobi National Park   \n",
       "4                 National Museum   \n",
       "\n",
       "                                         Description Country Continent  \\\n",
       "0  Amboseli belongs in the elite of Kenya’s natio...   Kenya    Africa   \n",
       "1  This 16th-century fort and Unesco World Herita...   Kenya    Africa   \n",
       "2  Occupying a plot within Nairobi National Park,...   Kenya    Africa   \n",
       "3  Welcome to Kenya’s most accessible yet incongr...   Kenya    Africa   \n",
       "4  Kenya’s wonderful National Museum, housed in a...   Kenya    Africa   \n",
       "\n",
       "                                             Cleaned  \n",
       "0  amboseli belongs in the elite of kenya’s natio...  \n",
       "1  this 16thcentury fort and unesco world heritag...  \n",
       "2  occupying a plot within nairobi national park ...  \n",
       "3  welcome to kenya’s most accessible yet incongr...  \n",
       "4  kenya’s wonderful national museum housed in an...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove commas, hyphens, colons, and other punctuation\n",
    "df_to_clean['Cleaned'] = df_to_clean['Cleaned'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))\n",
    "df_to_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attraction</th>\n",
       "      <th>Description</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amboseli National Park</td>\n",
       "      <td>Amboseli belongs in the elite of Kenya’s natio...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>amboseli belongs in the elite of kenya’s natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fort Jesus</td>\n",
       "      <td>This 16th-century fort and Unesco World Herita...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>this  fort and unesco world heritage treasure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Sheldrick Wildlife Trust</td>\n",
       "      <td>Occupying a plot within Nairobi National Park,...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>occupying a plot within nairobi national park ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nairobi National Park</td>\n",
       "      <td>Welcome to Kenya’s most accessible yet incongr...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>welcome to kenya’s most accessible yet incongr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>National Museum</td>\n",
       "      <td>Kenya’s wonderful National Museum, housed in a...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>kenya’s wonderful national museum housed in an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Giraffe Centre</td>\n",
       "      <td>This centre, which protects the highly endange...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>this centre which protects the highly endanger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lamu Museum</td>\n",
       "      <td>The best museum in town (and the second best i...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>the best museum in town and the second best in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Galana River</td>\n",
       "      <td>Running through the heart of the park and mark...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>running through the heart of the park and mark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mzima Springs</td>\n",
       "      <td>Mzima Springs is an oasis of green in the west...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>mzima springs is an oasis of green in the west...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ngulia Rhino Sanctuary</td>\n",
       "      <td>At the base of Ngulia Hills, this 90-sq-km are...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>at the base of ngulia hills this  area is surr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Attraction  \\\n",
       "0          Amboseli National Park   \n",
       "1                      Fort Jesus   \n",
       "2  David Sheldrick Wildlife Trust   \n",
       "3           Nairobi National Park   \n",
       "4                 National Museum   \n",
       "5                  Giraffe Centre   \n",
       "6                     Lamu Museum   \n",
       "7                    Galana River   \n",
       "8                   Mzima Springs   \n",
       "9          Ngulia Rhino Sanctuary   \n",
       "\n",
       "                                         Description Country Continent  \\\n",
       "0  Amboseli belongs in the elite of Kenya’s natio...   Kenya    Africa   \n",
       "1  This 16th-century fort and Unesco World Herita...   Kenya    Africa   \n",
       "2  Occupying a plot within Nairobi National Park,...   Kenya    Africa   \n",
       "3  Welcome to Kenya’s most accessible yet incongr...   Kenya    Africa   \n",
       "4  Kenya’s wonderful National Museum, housed in a...   Kenya    Africa   \n",
       "5  This centre, which protects the highly endange...   Kenya    Africa   \n",
       "6  The best museum in town (and the second best i...   Kenya    Africa   \n",
       "7  Running through the heart of the park and mark...   Kenya    Africa   \n",
       "8  Mzima Springs is an oasis of green in the west...   Kenya    Africa   \n",
       "9  At the base of Ngulia Hills, this 90-sq-km are...   Kenya    Africa   \n",
       "\n",
       "                                             Cleaned  \n",
       "0  amboseli belongs in the elite of kenya’s natio...  \n",
       "1  this  fort and unesco world heritage treasure ...  \n",
       "2  occupying a plot within nairobi national park ...  \n",
       "3  welcome to kenya’s most accessible yet incongr...  \n",
       "4  kenya’s wonderful national museum housed in an...  \n",
       "5  this centre which protects the highly endanger...  \n",
       "6  the best museum in town and the second best in...  \n",
       "7  running through the heart of the park and mark...  \n",
       "8  mzima springs is an oasis of green in the west...  \n",
       "9  at the base of ngulia hills this  area is surr...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use regex to get rid of numbers \n",
    "df_to_clean['Cleaned'] = df_to_clean['Cleaned'].apply(lambda x: re.sub('\\w*\\d\\w*','', x))\n",
    "df_to_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attraction</th>\n",
       "      <th>Description</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Cleaned</th>\n",
       "      <th>Lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amboseli National Park</td>\n",
       "      <td>Amboseli belongs in the elite of Kenya’s natio...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>amboseli belongs in the elite of kenya’s natio...</td>\n",
       "      <td>amboseli belong elite kenya national park easy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fort Jesus</td>\n",
       "      <td>This 16th-century fort and Unesco World Herita...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>this  fort and unesco world heritage treasure ...</td>\n",
       "      <td>fort unesco world heritage treasure mombasa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Sheldrick Wildlife Trust</td>\n",
       "      <td>Occupying a plot within Nairobi National Park,...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>occupying a plot within nairobi national park ...</td>\n",
       "      <td>occupy plot nairobi national park nonprofit tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nairobi National Park</td>\n",
       "      <td>Welcome to Kenya’s most accessible yet incongr...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>welcome to kenya’s most accessible yet incongr...</td>\n",
       "      <td>welcome kenya accessible incongruous safari ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>National Museum</td>\n",
       "      <td>Kenya’s wonderful National Museum, housed in a...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>kenya’s wonderful national museum housed in an...</td>\n",
       "      <td>kenya wonderful national museum house impose b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Giraffe Centre</td>\n",
       "      <td>This centre, which protects the highly endange...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>this centre which protects the highly endanger...</td>\n",
       "      <td>centre protect highly endanger rothschild gira...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lamu Museum</td>\n",
       "      <td>The best museum in town (and the second best i...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>the best museum in town and the second best in...</td>\n",
       "      <td>good museum town second good kenya house grand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Galana River</td>\n",
       "      <td>Running through the heart of the park and mark...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>running through the heart of the park and mark...</td>\n",
       "      <td>run heart park mark northernmost point park vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mzima Springs</td>\n",
       "      <td>Mzima Springs is an oasis of green in the west...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>mzima springs is an oasis of green in the west...</td>\n",
       "      <td>mzima spring oasis green west park produce inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ngulia Rhino Sanctuary</td>\n",
       "      <td>At the base of Ngulia Hills, this 90-sq-km are...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>at the base of ngulia hills this  area is surr...</td>\n",
       "      <td>base ngulia hill   area surround   electric fe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Attraction  \\\n",
       "0          Amboseli National Park   \n",
       "1                      Fort Jesus   \n",
       "2  David Sheldrick Wildlife Trust   \n",
       "3           Nairobi National Park   \n",
       "4                 National Museum   \n",
       "5                  Giraffe Centre   \n",
       "6                     Lamu Museum   \n",
       "7                    Galana River   \n",
       "8                   Mzima Springs   \n",
       "9          Ngulia Rhino Sanctuary   \n",
       "\n",
       "                                         Description Country Continent  \\\n",
       "0  Amboseli belongs in the elite of Kenya’s natio...   Kenya    Africa   \n",
       "1  This 16th-century fort and Unesco World Herita...   Kenya    Africa   \n",
       "2  Occupying a plot within Nairobi National Park,...   Kenya    Africa   \n",
       "3  Welcome to Kenya’s most accessible yet incongr...   Kenya    Africa   \n",
       "4  Kenya’s wonderful National Museum, housed in a...   Kenya    Africa   \n",
       "5  This centre, which protects the highly endange...   Kenya    Africa   \n",
       "6  The best museum in town (and the second best i...   Kenya    Africa   \n",
       "7  Running through the heart of the park and mark...   Kenya    Africa   \n",
       "8  Mzima Springs is an oasis of green in the west...   Kenya    Africa   \n",
       "9  At the base of Ngulia Hills, this 90-sq-km are...   Kenya    Africa   \n",
       "\n",
       "                                             Cleaned  \\\n",
       "0  amboseli belongs in the elite of kenya’s natio...   \n",
       "1  this  fort and unesco world heritage treasure ...   \n",
       "2  occupying a plot within nairobi national park ...   \n",
       "3  welcome to kenya’s most accessible yet incongr...   \n",
       "4  kenya’s wonderful national museum housed in an...   \n",
       "5  this centre which protects the highly endanger...   \n",
       "6  the best museum in town and the second best in...   \n",
       "7  running through the heart of the park and mark...   \n",
       "8  mzima springs is an oasis of green in the west...   \n",
       "9  at the base of ngulia hills this  area is surr...   \n",
       "\n",
       "                                          Lemmatized  \n",
       "0  amboseli belong elite kenya national park easy...  \n",
       "1    fort unesco world heritage treasure mombasa ...  \n",
       "2  occupy plot nairobi national park nonprofit tr...  \n",
       "3  welcome kenya accessible incongruous safari ex...  \n",
       "4  kenya wonderful national museum house impose b...  \n",
       "5  centre protect highly endanger rothschild gira...  \n",
       "6  good museum town second good kenya house grand...  \n",
       "7  run heart park mark northernmost point park vi...  \n",
       "8  mzima spring oasis green west park produce inc...  \n",
       "9  base ngulia hill   area surround   electric fe...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatize the text using spacy\n",
    "lemmatized = spacy.load('en_core_web_sm')\n",
    "\n",
    "df_to_clean['Lemmatized'] = df_to_clean['Cleaned'].apply(lambda x: ' '.join(\n",
    "                                    [token.lemma_ for token in list(lemmatized(x)) if (token.is_stop==False)]))\n",
    "df_to_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemmatized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>earth dynamic accessible ice field glaciar per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>definitively sydney bondi world great beach cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>tijuca s leave atlantic rainforest surround ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canada</th>\n",
       "      <td>canada sight banff national park justifiably r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chile</th>\n",
       "      <td>dub serengeti southern cone   parque nacional ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>cablehaule funicular railway scale   ascent hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Egypt</th>\n",
       "      <td>amunra local god karnak luxor new kingdom prin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiji</th>\n",
       "      <td>coloisuva pronounce tholoeesoova   oasis lush ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>fantastic space museum citys eastern outskirt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Germany</th>\n",
       "      <td>east gallery embodiment berlin grit gut cologn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>rise perpendicular impregnable rocky hill stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Israel</th>\n",
       "      <td>formal garden flow   steep terrace resplendent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>found pope julius ii early   century enlarge s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japan</th>\n",
       "      <td>fujisan japan revered timeless attraction insp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jordan</th>\n",
       "      <td>spectacular sandstone city petra build   centu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kenya</th>\n",
       "      <td>amboseli belong elite kenya national park easy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico</th>\n",
       "      <td>tulum visit archaeological zone mexico good re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morocco</th>\n",
       "      <td>french fashion designer yve saint laurent part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Zealand</th>\n",
       "      <td>maungakiekie large spiritually significant māo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peru</th>\n",
       "      <td>large lake cordillera blanca — snowcappe range...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Africa</th>\n",
       "      <td>location unique flora combine   botanical gard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thailand</th>\n",
       "      <td>wat pho absolute favorite bangkok big sight fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turkey</th>\n",
       "      <td>right heart i̇stanbul historic center sacred b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United Arab Emirates</th>\n",
       "      <td>burj al arabs graceful silhouette – mean evoke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>story smoky mountain begin primordial time cla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Lemmatized\n",
       "Country                                                                \n",
       "Argentina             earth dynamic accessible ice field glaciar per...\n",
       "Australia             definitively sydney bondi world great beach cl...\n",
       "Brazil                tijuca s leave atlantic rainforest surround ri...\n",
       "Canada                canada sight banff national park justifiably r...\n",
       "Chile                 dub serengeti southern cone   parque nacional ...\n",
       "China                 cablehaule funicular railway scale   ascent hi...\n",
       "Egypt                 amunra local god karnak luxor new kingdom prin...\n",
       "Fiji                  coloisuva pronounce tholoeesoova   oasis lush ...\n",
       "France                fantastic space museum citys eastern outskirt ...\n",
       "Germany               east gallery embodiment berlin grit gut cologn...\n",
       "India                 rise perpendicular impregnable rocky hill stan...\n",
       "Israel                formal garden flow   steep terrace resplendent...\n",
       "Italy                 found pope julius ii early   century enlarge s...\n",
       "Japan                 fujisan japan revered timeless attraction insp...\n",
       "Jordan                spectacular sandstone city petra build   centu...\n",
       "Kenya                 amboseli belong elite kenya national park easy...\n",
       "Mexico                tulum visit archaeological zone mexico good re...\n",
       "Morocco               french fashion designer yve saint laurent part...\n",
       "New Zealand           maungakiekie large spiritually significant māo...\n",
       "Peru                  large lake cordillera blanca — snowcappe range...\n",
       "South Africa          location unique flora combine   botanical gard...\n",
       "Thailand              wat pho absolute favorite bangkok big sight fa...\n",
       "Turkey                right heart i̇stanbul historic center sacred b...\n",
       "United Arab Emirates  burj al arabs graceful silhouette – mean evoke...\n",
       "United States         story smoky mountain begin primordial time cla..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group the corpora by Country and join them\n",
    "df_to_group = df_to_clean[['Country', 'Lemmatized']]\n",
    "df_grouped = df_to_group.groupby(by='Country').agg(lambda x:' '.join(x))\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at different vectorization strategies\n",
    "- Try different vectorization strategies and visualize them with word clouds  \n",
    "  - Count Vectorization\n",
    "  - TF-IDF Vectorization\n",
    "  - Bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aachen</th>\n",
       "      <th>aah</th>\n",
       "      <th>aalara</th>\n",
       "      <th>aalto</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaronsohn</th>\n",
       "      <th>aarti</th>\n",
       "      <th>aath</th>\n",
       "      <th>ab</th>\n",
       "      <th>abaca</th>\n",
       "      <th>...</th>\n",
       "      <th>饶平</th>\n",
       "      <th>骑楼</th>\n",
       "      <th>高北</th>\n",
       "      <th>鯉城</th>\n",
       "      <th>鸟巢</th>\n",
       "      <th>黄山</th>\n",
       "      <th>黄羊河水库</th>\n",
       "      <th>黑虎泉</th>\n",
       "      <th>黔灵山</th>\n",
       "      <th>龙潭</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canada</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chile</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           aachen  aah  aalara  aalto  aaron  aaronsohn  aarti  aath  ab  \\\n",
       "Country                                                                    \n",
       "Argentina       0    0       0      0      0          0      0     0   0   \n",
       "Australia       0    0       0      0      0          0      0     0   0   \n",
       "Brazil          0    0       0      0      0          0      0     0   0   \n",
       "Canada          0    0       0      0      0          0      0     0   0   \n",
       "Chile           0    0       0      0      0          0      0     0   0   \n",
       "\n",
       "           abaca  ...  饶平  骑楼  高北  鯉城  鸟巢  黄山  黄羊河水库  黑虎泉  黔灵山  龙潭  \n",
       "Country           ...                                               \n",
       "Argentina      0  ...   0   0   0   0   0   0      0    0    0   0  \n",
       "Australia      0  ...   0   0   0   0   0   0      0    0    0   0  \n",
       "Brazil         0  ...   0   0   0   0   0   0      0    0    0   0  \n",
       "Canada         0  ...   0   0   0   0   0   0      0    0    0   0  \n",
       "Chile          0  ...   0   0   0   0   0   0      0    0    0   0  \n",
       "\n",
       "[5 rows x 32172 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a document term matrix using count vectorization\n",
    "# Using count vectorization (most simple way to vectorize)\n",
    "cv = CountVectorizer(analyzer='word', stop_words=stopwords_list)\n",
    "data = cv.fit_transform(df_grouped['Lemmatized'])\n",
    "df_dtm = pd.DataFrame(data.toarray(), columns=cv.get_feature_names_out())\n",
    "df_dtm.index = df_grouped.index\n",
    "df_dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aachen</th>\n",
       "      <th>aah</th>\n",
       "      <th>aalara</th>\n",
       "      <th>aalto</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaronsohn</th>\n",
       "      <th>aarti</th>\n",
       "      <th>aath</th>\n",
       "      <th>ab</th>\n",
       "      <th>abaca</th>\n",
       "      <th>...</th>\n",
       "      <th>饶平</th>\n",
       "      <th>骑楼</th>\n",
       "      <th>高北</th>\n",
       "      <th>鯉城</th>\n",
       "      <th>鸟巢</th>\n",
       "      <th>黄山</th>\n",
       "      <th>黄羊河水库</th>\n",
       "      <th>黑虎泉</th>\n",
       "      <th>黔灵山</th>\n",
       "      <th>龙潭</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canada</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chile</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           aachen  aah  aalara  aalto  aaron  aaronsohn  aarti  aath   ab  \\\n",
       "Country                                                                     \n",
       "Argentina     0.0  0.0     0.0    0.0    0.0        0.0    0.0   0.0  0.0   \n",
       "Australia     0.0  0.0     0.0    0.0    0.0        0.0    0.0   0.0  0.0   \n",
       "Brazil        0.0  0.0     0.0    0.0    0.0        0.0    0.0   0.0  0.0   \n",
       "Canada        0.0  0.0     0.0    0.0    0.0        0.0    0.0   0.0  0.0   \n",
       "Chile         0.0  0.0     0.0    0.0    0.0        0.0    0.0   0.0  0.0   \n",
       "\n",
       "           abaca  ...   饶平   骑楼   高北   鯉城   鸟巢   黄山  黄羊河水库  黑虎泉  黔灵山   龙潭  \n",
       "Country           ...                                                      \n",
       "Argentina    0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  \n",
       "Australia    0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  \n",
       "Brazil       0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  \n",
       "Canada       0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  \n",
       "Chile        0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 32172 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a document term matrix using TF-IDF vectorization\n",
    "# Might be good for classifying cities\n",
    "tfidf = TfidfVectorizer(analyzer='word', stop_words=stopwords_list)\n",
    "data2 = tfidf.fit_transform(df_grouped['Lemmatized'])\n",
    "df_dtm2 = pd.DataFrame(data2.toarray(), columns=tfidf.get_feature_names_out())\n",
    "df_dtm2.index = df_grouped.index\n",
    "df_dtm2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Clouds with Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wordcloud(data, title):\n",
    "    cloud = WordCloud(width=400, height=330, max_words=150, colormap='tab20c').generate_from_frequencies(data)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.imshow(cloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('\\n'.join(wrap(title,60)), fontsize=13)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('museum', 2567),\n",
       " ('build', 1694),\n",
       " ('park', 1381),\n",
       " ('house', 1213),\n",
       " ('art', 1043),\n",
       " ('old', 1040),\n",
       " ('building', 992),\n",
       " ('temple', 968),\n",
       " ('city', 965),\n",
       " ('town', 962),\n",
       " ('small', 920),\n",
       " ('de', 881),\n",
       " ('large', 874),\n",
       " ('beach', 850),\n",
       " ('church', 844)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at top words with count vectorizer (in total, not per country)\n",
    "sum_words = data.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\n",
    "words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "words_freq[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the top words is 'km', short for kilometer which does not point to anything unique in a country. Others are small, large, de(Frech for of), Include, Know, like, sq, la, di, and ad. We could consider adding these to the stop words list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Clouds with TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('museum', 4.338283338806132),\n",
       " ('build', 2.847216592794639),\n",
       " ('park', 2.5753723067208036),\n",
       " ('house', 2.102425356015084),\n",
       " ('de', 2.059704840493331),\n",
       " ('art', 1.7656707773228493),\n",
       " ('building', 1.7376203154296406),\n",
       " ('small', 1.6824509665578642),\n",
       " ('city', 1.6807341150324604),\n",
       " ('old', 1.6741619719375596),\n",
       " ('temple', 1.629421021562768),\n",
       " ('town', 1.6075814968969786),\n",
       " ('beach', 1.573155156763898),\n",
       " ('church', 1.5325291672646273),\n",
       " ('large', 1.4327499375576518)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at top words with tf-idf vectorization (for total words, not per country)\n",
    "sum_words = data2.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in tfidf.vocabulary_.items()]\n",
    "words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "words_freq[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very similar to the top words to count vectorication, with words like km, de,include, being repeated. However, there is no much overlap since TF-IFD finds more words thata re unique to the countries, telling is that this is probably a better technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('national park', 303),\n",
       " ('de la', 131),\n",
       " ('small museum', 129),\n",
       " ('museum house', 119),\n",
       " ('date century', 101),\n",
       " ('old town', 99),\n",
       " ('art museum', 95),\n",
       " ('sq km', 92),\n",
       " ('contemporary art', 86),\n",
       " ('build century', 86),\n",
       " ('museum display', 84),\n",
       " ('art gallery', 82),\n",
       " ('world heritage', 79),\n",
       " ('look like', 72),\n",
       " ('worth visit', 68)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2 = CountVectorizer(analyzer='word', stop_words=stopwords_list, ngram_range=(2,2))\n",
    "data3 = cv2.fit_transform(df_grouped['Lemmatized'])\n",
    "df_dtm3 = pd.DataFrame(data3.toarray(), columns=cv2.get_feature_names_out())\n",
    "df_dtm3.index = df_grouped.index\n",
    "df_dtm3\n",
    "# Transposing document term matrix\n",
    "df_dtm3 = df_dtm3.transpose()\n",
    "# Look at top bi-grams (in total, not per country)\n",
    "sum_words = data3.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in cv2.vocabulary_.items()]\n",
    "words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "words_freq[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a better indication of the words that we should remove since they are creating noise in the data but are commonly featured in the countries. These are:\n",
    "- sq, km, south, north, west, east, de, la, southeast, northeast, northwest, look, like, southwest, de, san, and northern. Now that we have confirmation, we will add them to our stop words lists to make our data cleaner for visualizations and analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Noise from the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to remove these words that are not unique to countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add hese words to the stopwords list\n",
    "stopwords_list += ['sq', 'km', 'south', 'west', 'north', 'east', 'de', 'la', 'southeast', 'northeast', 'northwest', 'look', 'like', 'southwest', 'de', 'san', 'northern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('national park', 303),\n",
       " ('small museum', 129),\n",
       " ('museum house', 119),\n",
       " ('date century', 101),\n",
       " ('old town', 99),\n",
       " ('art museum', 95),\n",
       " ('contemporary art', 86),\n",
       " ('build century', 86),\n",
       " ('museum display', 84),\n",
       " ('art gallery', 82),\n",
       " ('world heritage', 79),\n",
       " ('worth visit', 68),\n",
       " ('early century', 67),\n",
       " ('buddhist temple', 66),\n",
       " ('world large', 65)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether this has worked.\n",
    "cv2 = CountVectorizer(analyzer='word', stop_words=stopwords_list, ngram_range=(2,2))\n",
    "data3 = cv2.fit_transform(df_grouped['Lemmatized'])\n",
    "df_dtm3 = pd.DataFrame(data3.toarray(), columns=cv2.get_feature_names_out())\n",
    "df_dtm3.index = df_grouped.index\n",
    "df_dtm3\n",
    "# Transposing document term matrix\n",
    "df_dtm3 = df_dtm3.transpose()\n",
    "# Look at top bi-grams (in total, not per country)\n",
    "sum_words = data3.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in cv2.vocabulary_.items()]\n",
    "words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "words_freq[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attraction</th>\n",
       "      <th>Description</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amboseli National Park</td>\n",
       "      <td>Amboseli belongs in the elite of Kenya’s natio...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fort Jesus</td>\n",
       "      <td>This 16th-century fort and Unesco World Herita...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Sheldrick Wildlife Trust</td>\n",
       "      <td>Occupying a plot within Nairobi National Park,...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nairobi National Park</td>\n",
       "      <td>Welcome to Kenya’s most accessible yet incongr...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>National Museum</td>\n",
       "      <td>Kenya’s wonderful National Museum, housed in a...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Attraction  \\\n",
       "0          Amboseli National Park   \n",
       "1                      Fort Jesus   \n",
       "2  David Sheldrick Wildlife Trust   \n",
       "3           Nairobi National Park   \n",
       "4                 National Museum   \n",
       "\n",
       "                                         Description Country Continent  \n",
       "0  Amboseli belongs in the elite of Kenya’s natio...   Kenya    Africa  \n",
       "1  This 16th-century fort and Unesco World Herita...   Kenya    Africa  \n",
       "2  Occupying a plot within Nairobi National Park,...   Kenya    Africa  \n",
       "3  Welcome to Kenya’s most accessible yet incongr...   Kenya    Africa  \n",
       "4  Kenya’s wonderful National Museum, housed in a...   Kenya    Africa  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions To Make Preprocessing Easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df, column, preview=True, lemmatize=True):\n",
    "    \"\"\"\n",
    "    Input df with raw text descriptions.\n",
    "    Return df with preprocessed text.\n",
    "    If preview=True, returns a preview of the new df.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    df[column] = df['Description'].apply(lambda x: x.lower())\n",
    "    df[column] = df[column].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))\n",
    "    df[column] = df[column].apply(lambda x: re.sub('\\w*\\d\\w*','', x))\n",
    "    \n",
    "\n",
    "    if lemmatize:\n",
    "        df[column]= df[column].apply(lambda x: ' '.join(\n",
    "                                    [token.lemma_ for token in list(lemmatized(x)) if (token.is_stop==False)]))\n",
    "    \n",
    "\n",
    "    if preview:\n",
    "        display(df.head(10))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_text_per_country(df, column):\n",
    "    \"\"\"\n",
    "    Groups the preprocessed text per country.\n",
    "    \"\"\"\n",
    "    df_to_group = df[['Country', column]]\n",
    "    df_grouped = df_to_group.groupby(by='Country').agg(lambda x:' '.join(x))\n",
    "    return df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_doc_term_matrix(df, column, count_vec=True, ngram_range=(1,1)):\n",
    "    \"\"\"\n",
    "    Creates a document term matrix.\n",
    "    Defaults to count vectorizer with optional n-gram param.\n",
    "    If count_vec==False, uses a TF-IDF vectorizer.\n",
    "    \"\"\"\n",
    "    df_grouped = group_text_per_country(df, column)\n",
    "    \n",
    "    if count_vec:\n",
    "        vec = CountVectorizer(analyzer='word', stop_words=stopwords_list, ngram_range=ngram_range)\n",
    "    else:\n",
    "        vec = TfidfVectorizer(analyzer='word', stop_words=stopwords_list)\n",
    "    \n",
    "    data = vec.fit_transform(df_grouped[column])\n",
    "    df_dtm = pd.DataFrame(data.toarray(), columns=vec.get_feature_names_out())\n",
    "    df_dtm.index = df_grouped.index\n",
    "    return df_dtm.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attraction</th>\n",
       "      <th>Description</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amboseli National Park</td>\n",
       "      <td>Amboseli belongs in the elite of Kenya’s natio...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>amboseli belong elite kenya national park easy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fort Jesus</td>\n",
       "      <td>This 16th-century fort and Unesco World Herita...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>fort unesco world heritage treasure mombasa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Sheldrick Wildlife Trust</td>\n",
       "      <td>Occupying a plot within Nairobi National Park,...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>occupy plot nairobi national park nonprofit tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nairobi National Park</td>\n",
       "      <td>Welcome to Kenya’s most accessible yet incongr...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>welcome kenya accessible incongruous safari ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>National Museum</td>\n",
       "      <td>Kenya’s wonderful National Museum, housed in a...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>kenya wonderful national museum house impose b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Giraffe Centre</td>\n",
       "      <td>This centre, which protects the highly endange...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>centre protect highly endanger rothschild gira...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lamu Museum</td>\n",
       "      <td>The best museum in town (and the second best i...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>good museum town second good kenya house grand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Galana River</td>\n",
       "      <td>Running through the heart of the park and mark...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>run heart park mark northernmost point park vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mzima Springs</td>\n",
       "      <td>Mzima Springs is an oasis of green in the west...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>mzima spring oasis green west park produce inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ngulia Rhino Sanctuary</td>\n",
       "      <td>At the base of Ngulia Hills, this 90-sq-km are...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>base ngulia hill   area surround   electric fe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Attraction  \\\n",
       "0          Amboseli National Park   \n",
       "1                      Fort Jesus   \n",
       "2  David Sheldrick Wildlife Trust   \n",
       "3           Nairobi National Park   \n",
       "4                 National Museum   \n",
       "5                  Giraffe Centre   \n",
       "6                     Lamu Museum   \n",
       "7                    Galana River   \n",
       "8                   Mzima Springs   \n",
       "9          Ngulia Rhino Sanctuary   \n",
       "\n",
       "                                         Description Country Continent  \\\n",
       "0  Amboseli belongs in the elite of Kenya’s natio...   Kenya    Africa   \n",
       "1  This 16th-century fort and Unesco World Herita...   Kenya    Africa   \n",
       "2  Occupying a plot within Nairobi National Park,...   Kenya    Africa   \n",
       "3  Welcome to Kenya’s most accessible yet incongr...   Kenya    Africa   \n",
       "4  Kenya’s wonderful National Museum, housed in a...   Kenya    Africa   \n",
       "5  This centre, which protects the highly endange...   Kenya    Africa   \n",
       "6  The best museum in town (and the second best i...   Kenya    Africa   \n",
       "7  Running through the heart of the park and mark...   Kenya    Africa   \n",
       "8  Mzima Springs is an oasis of green in the west...   Kenya    Africa   \n",
       "9  At the base of Ngulia Hills, this 90-sq-km are...   Kenya    Africa   \n",
       "\n",
       "                                          Lemmatized  \n",
       "0  amboseli belong elite kenya national park easy...  \n",
       "1    fort unesco world heritage treasure mombasa ...  \n",
       "2  occupy plot nairobi national park nonprofit tr...  \n",
       "3  welcome kenya accessible incongruous safari ex...  \n",
       "4  kenya wonderful national museum house impose b...  \n",
       "5  centre protect highly endanger rothschild gira...  \n",
       "6  good museum town second good kenya house grand...  \n",
       "7  run heart park mark northernmost point park vi...  \n",
       "8  mzima spring oasis green west park produce inc...  \n",
       "9  base ngulia hill   area surround   electric fe...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attraction</th>\n",
       "      <th>Description</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amboseli National Park</td>\n",
       "      <td>Amboseli belongs in the elite of Kenya’s natio...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>amboseli belong elite kenya national park easy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fort Jesus</td>\n",
       "      <td>This 16th-century fort and Unesco World Herita...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>fort unesco world heritage treasure mombasa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Sheldrick Wildlife Trust</td>\n",
       "      <td>Occupying a plot within Nairobi National Park,...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>occupy plot nairobi national park nonprofit tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nairobi National Park</td>\n",
       "      <td>Welcome to Kenya’s most accessible yet incongr...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>welcome kenya accessible incongruous safari ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>National Museum</td>\n",
       "      <td>Kenya’s wonderful National Museum, housed in a...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>kenya wonderful national museum house impose b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18035</th>\n",
       "      <td>Byzantine Basilica</td>\n",
       "      <td>Near the Citadel's archaeological museum is th...</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>near citadels archaeological museum small byza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18036</th>\n",
       "      <td>Sharif Al Hussein Bin Ali Mosque</td>\n",
       "      <td>This grand and beautiful gleaming white mosque...</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>grand beautiful gleam white mosque – icon aqab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18037</th>\n",
       "      <td>North Theatre</td>\n",
       "      <td>The North Theatre is overgrown and missing muc...</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>north theatre overgrown miss original blackbas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18038</th>\n",
       "      <td>Shops</td>\n",
       "      <td>The shells of a row of shops remain in the wes...</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>shell row shop remain western section colonnad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18039</th>\n",
       "      <td>Rakhabat Canyon</td>\n",
       "      <td>Close to Rum village, the labyrinthine siqs of...</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>close rum village labyrinthine siqs rakhabat c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18031 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Attraction  \\\n",
       "0                Amboseli National Park   \n",
       "1                            Fort Jesus   \n",
       "2        David Sheldrick Wildlife Trust   \n",
       "3                 Nairobi National Park   \n",
       "4                       National Museum   \n",
       "...                                 ...   \n",
       "18035                Byzantine Basilica   \n",
       "18036  Sharif Al Hussein Bin Ali Mosque   \n",
       "18037                     North Theatre   \n",
       "18038                             Shops   \n",
       "18039                   Rakhabat Canyon   \n",
       "\n",
       "                                             Description Country    Continent  \\\n",
       "0      Amboseli belongs in the elite of Kenya’s natio...   Kenya       Africa   \n",
       "1      This 16th-century fort and Unesco World Herita...   Kenya       Africa   \n",
       "2      Occupying a plot within Nairobi National Park,...   Kenya       Africa   \n",
       "3      Welcome to Kenya’s most accessible yet incongr...   Kenya       Africa   \n",
       "4      Kenya’s wonderful National Museum, housed in a...   Kenya       Africa   \n",
       "...                                                  ...     ...          ...   \n",
       "18035  Near the Citadel's archaeological museum is th...  Jordan  Middle East   \n",
       "18036  This grand and beautiful gleaming white mosque...  Jordan  Middle East   \n",
       "18037  The North Theatre is overgrown and missing muc...  Jordan  Middle East   \n",
       "18038  The shells of a row of shops remain in the wes...  Jordan  Middle East   \n",
       "18039  Close to Rum village, the labyrinthine siqs of...  Jordan  Middle East   \n",
       "\n",
       "                                              Lemmatized  \n",
       "0      amboseli belong elite kenya national park easy...  \n",
       "1        fort unesco world heritage treasure mombasa ...  \n",
       "2      occupy plot nairobi national park nonprofit tr...  \n",
       "3      welcome kenya accessible incongruous safari ex...  \n",
       "4      kenya wonderful national museum house impose b...  \n",
       "...                                                  ...  \n",
       "18035  near citadels archaeological museum small byza...  \n",
       "18036  grand beautiful gleam white mosque – icon aqab...  \n",
       "18037  north theatre overgrown miss original blackbas...  \n",
       "18038  shell row shop remain western section colonnad...  \n",
       "18039  close rum village labyrinthine siqs rakhabat c...  \n",
       "\n",
       "[18031 rows x 5 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df = preprocess_df(df, 'Lemmatized')\n",
    "preprocessed_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZATIONS FOR ALL COUNTRIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('museum', 2567),\n",
       " ('build', 1694),\n",
       " ('park', 1381),\n",
       " ('house', 1213),\n",
       " ('art', 1043),\n",
       " ('old', 1040),\n",
       " ('building', 992),\n",
       " ('temple', 968),\n",
       " ('city', 965),\n",
       " ('town', 962),\n",
       " ('small', 920),\n",
       " ('de', 881),\n",
       " ('large', 874),\n",
       " ('beach', 850),\n",
       " ('church', 844)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top Words After All the Preprocessing Steps (In total for all the countries)\n",
    "sum_words = data.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\n",
    "words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "words_freq[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Words for All The Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 15 top words in total\n",
    "words_freq_df = pd.DataFrame(words_freq[:15], columns=['Word', 'Frequency'])\n",
    "words_freq_df\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x='Frequency', y='Word', data=words_freq_df, palette='icefire')\n",
    "plt.title('Attractions Per Country')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Cloud for Top 15 words in Total\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert word frequencies into a dictionary\n",
    "word_freq_dict = dict(words_freq)\n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud = WordCloud(width=400, height=400, max_words=50, colormap='viridis', contour_width=1, contour_color='steelblue', background_color='white').generate_from_frequencies(word_freq_dict)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Bi-Grams For All the Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('national park', 303),\n",
       " ('small museum', 129),\n",
       " ('museum house', 119),\n",
       " ('date century', 101),\n",
       " ('old town', 99),\n",
       " ('art museum', 95),\n",
       " ('contemporary art', 86),\n",
       " ('build century', 86),\n",
       " ('museum display', 84),\n",
       " ('art gallery', 82),\n",
       " ('world heritage', 79),\n",
       " ('worth visit', 68),\n",
       " ('early century', 67),\n",
       " ('buddhist temple', 66),\n",
       " ('world large', 65)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top Bi-Grams for All the Countries \n",
    "cv3 = CountVectorizer(analyzer='word', stop_words=stopwords_list, ngram_range=(2,2))\n",
    "df_grouped = group_text_per_country(preprocessed_df, 'Lemmatized')\n",
    "data4 = cv3.fit_transform(df_grouped['Lemmatized'])\n",
    "df_dtm4 = pd.DataFrame(data4.toarray(), columns=cv3.get_feature_names_out())\n",
    "df_dtm4.index = df_grouped.index\n",
    "df_dtm4\n",
    "# Transposing document term matrix\n",
    "df_dtm4 = df_dtm4.transpose()\n",
    "# Look at top bi-grams (in total, not per country)\n",
    "sum_words = data4.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in cv3.vocabulary_.items()]\n",
    "words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "words_freq[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 15 top Bi-Grams in total\n",
    "words_freq_bi_df = pd.DataFrame(words_freq[:15], columns=['Word', 'Frequency'])\n",
    "words_freq_bi_df\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.barplot(x='Frequency', y='Word', data=words_freq_bi_df, palette='icefire')\n",
    "plt.title('Top Bi-Grams Overall')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Cloud for Top 15 BI-Grams in Total\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert word frequencies into a dictionary\n",
    "word_freq_dict = dict(words_freq)\n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud = WordCloud(width=400, max_words=50, height=400, colormap='viridis', contour_width=1, contour_color='steelblue', background_color='white').generate_from_frequencies(word_freq_dict)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Tri-Grams for All Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('world heritage site', 47),\n",
       " ('unesco world heritage', 46),\n",
       " ('national historic site', 21),\n",
       " ('museum tell story', 20),\n",
       " ('world heritage list', 18),\n",
       " ('final resting place', 16),\n",
       " ('national park cover', 15),\n",
       " ('date early century', 14),\n",
       " ('traditional ornately decorate', 12),\n",
       " ('ornately decorate residence', 12),\n",
       " ('world large collection', 11),\n",
       " ('museum worth visit', 11),\n",
       " ('large national park', 10),\n",
       " ('art gallery house', 10),\n",
       " ('haveli traditional ornately', 10)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top Tri-Grams for All the Countries \n",
    "cv4 = CountVectorizer(analyzer='word', stop_words=stopwords_list, ngram_range=(3,3))\n",
    "df_grouped = group_text_per_country(preprocessed_df, 'Lemmatized')\n",
    "data5 = cv4.fit_transform(df_grouped['Lemmatized'])\n",
    "df_dtm5 = pd.DataFrame(data5.toarray(), columns=cv4.get_feature_names_out())\n",
    "df_dtm5.index = df_grouped.index\n",
    "df_dtm5\n",
    "# Transposing document term matrix\n",
    "df_dtm5 = df_dtm5.transpose()\n",
    "# Look at top tri-grams (in total, not per country)\n",
    "sum_words = data5.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in cv4.vocabulary_.items()]\n",
    "words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "words_freq[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 15 top Tri-Grams in total\n",
    "words_freq_tri_df = pd.DataFrame(words_freq[:15], columns=['Word', 'Frequency'])\n",
    "words_freq_tri_df\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x='Frequency', y='Word', data=words_freq_tri_df, palette='icefire')\n",
    "plt.title('Description of Top Attractions')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Cloud for Top 15 Tri-Grams in Total\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert word frequencies into a dictionary\n",
    "word_freq_dict = dict(words_freq)\n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud = WordCloud(width=600, max_words=50, height=400, colormap='viridis', contour_width=1, contour_color='steelblue', background_color='white').generate_from_frequencies(word_freq_dict)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZATIONS FOR KENYA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attraction</th>\n",
       "      <th>Description</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amboseli National Park</td>\n",
       "      <td>Amboseli belongs in the elite of Kenya’s natio...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>amboseli belong elite kenya national park easy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fort Jesus</td>\n",
       "      <td>This 16th-century fort and Unesco World Herita...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>fort unesco world heritage treasure mombasa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Sheldrick Wildlife Trust</td>\n",
       "      <td>Occupying a plot within Nairobi National Park,...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>occupy plot nairobi national park nonprofit tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nairobi National Park</td>\n",
       "      <td>Welcome to Kenya’s most accessible yet incongr...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>welcome kenya accessible incongruous safari ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>National Museum</td>\n",
       "      <td>Kenya’s wonderful National Museum, housed in a...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>kenya wonderful national museum house impose b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Malindi Museum</td>\n",
       "      <td>Part of the Malindi Historic Circuit, this mod...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>malindi historic circuit moderately interestin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Lake Oloiden</td>\n",
       "      <td>Lake Naivasha may be a freshwater lake, but it...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>lake naivasha freshwater lake alkaline water n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Portuguese Church</td>\n",
       "      <td>This thatched-roofed church gets its name beca...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>thatchedroofe church get portuguese explorer v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Lamu Market</td>\n",
       "      <td>Atmospheric and somewhat chaotic, this quintes...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>atmospheric somewhat chaotic quintessential la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Buffalo Springs National Reserve</td>\n",
       "      <td>The twin sister of Samburu National Reserve, w...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "      <td>twin sister samburu national reserve sit oppos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Attraction  \\\n",
       "0              Amboseli National Park   \n",
       "1                          Fort Jesus   \n",
       "2      David Sheldrick Wildlife Trust   \n",
       "3               Nairobi National Park   \n",
       "4                     National Museum   \n",
       "..                                ...   \n",
       "155                    Malindi Museum   \n",
       "156                      Lake Oloiden   \n",
       "157                 Portuguese Church   \n",
       "158                       Lamu Market   \n",
       "159  Buffalo Springs National Reserve   \n",
       "\n",
       "                                           Description Country Continent  \\\n",
       "0    Amboseli belongs in the elite of Kenya’s natio...   Kenya    Africa   \n",
       "1    This 16th-century fort and Unesco World Herita...   Kenya    Africa   \n",
       "2    Occupying a plot within Nairobi National Park,...   Kenya    Africa   \n",
       "3    Welcome to Kenya’s most accessible yet incongr...   Kenya    Africa   \n",
       "4    Kenya’s wonderful National Museum, housed in a...   Kenya    Africa   \n",
       "..                                                 ...     ...       ...   \n",
       "155  Part of the Malindi Historic Circuit, this mod...   Kenya    Africa   \n",
       "156  Lake Naivasha may be a freshwater lake, but it...   Kenya    Africa   \n",
       "157  This thatched-roofed church gets its name beca...   Kenya    Africa   \n",
       "158  Atmospheric and somewhat chaotic, this quintes...   Kenya    Africa   \n",
       "159  The twin sister of Samburu National Reserve, w...   Kenya    Africa   \n",
       "\n",
       "                                            Lemmatized  \n",
       "0    amboseli belong elite kenya national park easy...  \n",
       "1      fort unesco world heritage treasure mombasa ...  \n",
       "2    occupy plot nairobi national park nonprofit tr...  \n",
       "3    welcome kenya accessible incongruous safari ex...  \n",
       "4    kenya wonderful national museum house impose b...  \n",
       "..                                                 ...  \n",
       "155  malindi historic circuit moderately interestin...  \n",
       "156  lake naivasha freshwater lake alkaline water n...  \n",
       "157  thatchedroofe church get portuguese explorer v...  \n",
       "158  atmospheric somewhat chaotic quintessential la...  \n",
       "159  twin sister samburu national reserve sit oppos...  \n",
       "\n",
       "[160 rows x 5 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DF for Kenya only \n",
    "kenya_df = preprocessed_df[preprocessed_df['Country'] == 'Kenya']\n",
    "kenya_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_kenya = cv.fit_transform(kenya_df['Lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data_kenya: (160, 1134)\n",
      "Size of cv.vocabulary_: 1134\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of data_kenya:\", data_kenya.shape)\n",
    "print(\"Size of cv.vocabulary_:\", len(cv.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('park', 43),\n",
       " ('national', 27),\n",
       " ('kenya', 19),\n",
       " ('hill', 19),\n",
       " ('lake', 19),\n",
       " ('nairobi', 16),\n",
       " ('house', 12),\n",
       " ('good', 12),\n",
       " ('place', 12),\n",
       " ('visit', 11),\n",
       " ('area', 11),\n",
       " ('forest', 11),\n",
       " ('reserve', 10),\n",
       " ('view', 10),\n",
       " ('museum', 9)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum word occurrences across all rows\n",
    "sum_words_kenya = data_kenya.sum(axis=0)\n",
    "\n",
    "# Extract word frequencies\n",
    "words_freq_kenya = [(word, sum_words_kenya[0, idx]) for word, idx in cv.vocabulary_.items()]\n",
    "\n",
    "# Sort by frequency in descending order\n",
    "words_freq_kenya = sorted(words_freq_kenya, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display the result\n",
    "words_freq_kenya[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Words for Kenya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 15 top words in total for Kenya\n",
    "words_freq_df_kenya = pd.DataFrame(words_freq_kenya[:15], columns=['Word', 'Frequency'])\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x='Frequency', y='Word', data=words_freq_df_kenya, palette='icefire')\n",
    "plt.title('Top Descriptions for Atrractions in Kenya Kenya')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Cloud for Top 15 Words in Kenya\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert word frequencies into a dictionary\n",
    "word_freq_dict = dict(words_freq_kenya)\n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud = WordCloud(width=600, max_words=50, height=400, colormap='viridis', contour_width=1, contour_color='steelblue', background_color='white').generate_from_frequencies(word_freq_dict)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Bi-Grams for Kenya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('national park', 18),\n",
       " ('nairobi national', 7),\n",
       " ('national reserve', 6),\n",
       " ('white sand', 4),\n",
       " ('world heritage', 3),\n",
       " ('voi gate', 3),\n",
       " ('wildlife sanctuary', 3),\n",
       " ('taita hill', 3),\n",
       " ('good place', 3),\n",
       " ('lake turkana', 3),\n",
       " ('park easy', 2),\n",
       " ('unesco world', 2),\n",
       " ('national museum', 2),\n",
       " ('rothschild giraffe', 2),\n",
       " ('run heart', 2)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top Bi-Grams for Kenya\n",
    "\n",
    "cv_Kenya_bi = CountVectorizer(analyzer='word', stop_words=stopwords_list, ngram_range=(2,2))\n",
    "kenya_grouped = group_text_per_country(kenya_df, 'Lemmatized')\n",
    "data_kenya_bi = cv_Kenya_bi.fit_transform(kenya_df['Lemmatized'])\n",
    "df_dtm_kenya = pd.DataFrame(data_kenya_bi.toarray(), columns=cv_Kenya_bi.get_feature_names_out())\n",
    "\n",
    "\n",
    "# # Transposing document term matrix\n",
    "df_dtm_kenya = df_dtm_kenya.transpose()\n",
    "# # Look at top bi-grams \n",
    "sum_words_bi = data_kenya_bi.sum(axis=0)\n",
    "words_freq_bi = [(word, sum_words_bi[0, idx]) for word, idx in cv_Kenya_bi.vocabulary_.items()]\n",
    "words_freq_bi = sorted(words_freq_bi, key=lambda x: x[1], reverse=True)\n",
    "words_freq_bi[:15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 15 top Bi-Grams in total for Kenya\n",
    "words_freq_bi_df_kenya = pd.DataFrame(words_freq_bi[:15], columns=['Word', 'Frequency'])\n",
    "words_freq_bi_df_kenya\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x='Frequency', y='Word', data=words_freq_bi_df_kenya, palette='icefire')\n",
    "plt.title('Top Bi-Grams Overall for Kenya')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Cloud for Top 15 Bi-grams in Kenya\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert word frequencies into a dictionary\n",
    "word_freq_dict = dict(words_freq_bi)\n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud = WordCloud(width=600, max_words=50, height=400, colormap='viridis', contour_width=1, contour_color='steelblue', background_color='white').generate_from_frequencies(word_freq_dict)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Tri-Grams for Kenya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nairobi national park', 7),\n",
       " ('unesco world heritage', 2),\n",
       " ('run heart park', 2),\n",
       " ('kenya large national', 2),\n",
       " ('large national park', 2),\n",
       " ('tsavo national park', 2),\n",
       " ('shetani lava flow', 2),\n",
       " ('lava flow shetani', 2),\n",
       " ('fivehour return hike', 2),\n",
       " ('return hike lirhanda', 2),\n",
       " ('hike lirhanda hill', 2),\n",
       " ('world heritage site', 2),\n",
       " ('blue post hotel', 2),\n",
       " ('portuguese explorer vasco', 2),\n",
       " ('explorer vasco da', 2)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top Tri-Grams for Kenya\n",
    "\n",
    "\n",
    "cv_Kenya_tri = CountVectorizer(analyzer='word', stop_words=stopwords_list, ngram_range=(3,3))\n",
    "kenya_grouped = group_text_per_country(kenya_df, 'Lemmatized')\n",
    "data_kenya_tri = cv_Kenya_tri.fit_transform(kenya_df['Lemmatized'])\n",
    "df_dtm_kenya_tri = pd.DataFrame(data_kenya_tri.toarray(), columns=cv_Kenya_tri.get_feature_names_out())\n",
    "\n",
    "\n",
    "# # Transposing document term matrix\n",
    "df_dtm_kenya_tri = df_dtm_kenya_tri.transpose()\n",
    "# # Look at top bi-grams \n",
    "sum_words_tri = data_kenya_tri.sum(axis=0)\n",
    "words_freq_tri = [(word, sum_words_tri[0, idx]) for word, idx in cv_Kenya_tri.vocabulary_.items()]\n",
    "words_freq_tri = sorted(words_freq_tri, key=lambda x: x[1], reverse=True)\n",
    "words_freq_tri[:15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 15 top Tri-Grams in total for Kenya\n",
    "words_freq_tri_df_kenya = pd.DataFrame(words_freq_tri[:15], columns=['Word', 'Frequency'])\n",
    "words_freq_tri_df_kenya\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x='Frequency', y='Word', data=words_freq_tri_df_kenya, palette='icefire')\n",
    "plt.title('Top Tri-Grams Overall for Kenya')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Cloud for Top 15 Tri-grams in Kenya\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert word frequencies into a dictionary\n",
    "word_freq_dict = dict(words_freq_tri)\n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud = WordCloud(width=600, max_words=50, height=400, colormap='viridis', contour_width=1, contour_color='steelblue', background_color='white').generate_from_frequencies(word_freq_dict)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Analyze the common descriptors used for top destinations on travel websites, using Lonely Planet's sample data as a benchmark.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Compare attraction distribution across countries to identify imbalances, using Lonely Planet's sample data as a benchmark. Determine which countries are overrepresented on travel websites.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Analyze international travel websites' marketing for Kenyan destinations. Identify popular locations and descriptive language used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attraction</th>\n",
       "      <th>Description</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amboseli National Park</td>\n",
       "      <td>Amboseli belongs in the elite of Kenya’s natio...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fort Jesus</td>\n",
       "      <td>This 16th-century fort and Unesco World Herita...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Sheldrick Wildlife Trust</td>\n",
       "      <td>Occupying a plot within Nairobi National Park,...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nairobi National Park</td>\n",
       "      <td>Welcome to Kenya’s most accessible yet incongr...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>National Museum</td>\n",
       "      <td>Kenya’s wonderful National Museum, housed in a...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Attraction  \\\n",
       "0          Amboseli National Park   \n",
       "1                      Fort Jesus   \n",
       "2  David Sheldrick Wildlife Trust   \n",
       "3           Nairobi National Park   \n",
       "4                 National Museum   \n",
       "\n",
       "                                         Description Country Continent  \n",
       "0  Amboseli belongs in the elite of Kenya’s natio...   Kenya    Africa  \n",
       "1  This 16th-century fort and Unesco World Herita...   Kenya    Africa  \n",
       "2  Occupying a plot within Nairobi National Park,...   Kenya    Africa  \n",
       "3  Welcome to Kenya’s most accessible yet incongr...   Kenya    Africa  \n",
       "4  Kenya’s wonderful National Museum, housed in a...   Kenya    Africa  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-import the data to get a fresh start\n",
    "data = pd.read_csv('/Users//rosew/Downloads/best_travel_destinations_for_2025_df_cleaned.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14424,), (3607,))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform train-test split before cleaning.preprocessing\n",
    "X = data['Description']\n",
    "y= data['Country']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119      A watering hole that attracts animals, includi...\n",
       "9709     This museum offers a good overview of the natu...\n",
       "11414    Formed as early as 1977 from a desire to prese...\n",
       "4584     One of the few nature sanctuaries within day-t...\n",
       "12856    This small plantation, which produces almost-o...\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since this is a series, it will need to be changed to a DF for preprocessing\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>A watering hole that attracts animals, includi...</td>\n",
       "      <td>watering hole attract animal include elephant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9709</th>\n",
       "      <td>This museum offers a good overview of the natu...</td>\n",
       "      <td>museum offer good overview natural cultural hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11414</th>\n",
       "      <td>Formed as early as 1977 from a desire to prese...</td>\n",
       "      <td>form early   desire preserve memory story poss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4584</th>\n",
       "      <td>One of the few nature sanctuaries within day-t...</td>\n",
       "      <td>nature sanctuary daytrip reach mumbais city li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12856</th>\n",
       "      <td>This small plantation, which produces almost-o...</td>\n",
       "      <td>small plantation produce almostorganic shadegr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4622</th>\n",
       "      <td>A few partially rebuilt wall stubs are all tha...</td>\n",
       "      <td>partially rebuild wall stub remain palace comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16990</th>\n",
       "      <td>The Roman harbour at the base of Kaleiçi's slo...</td>\n",
       "      <td>roman harbour base kaleiçis slope antalyas lif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9767</th>\n",
       "      <td>Was it the fall of 1966 or the winter of ’67? ...</td>\n",
       "      <td>fall   winter ' haight saying go remember summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12534</th>\n",
       "      <td>Staff at the visitors center of the stunning C...</td>\n",
       "      <td>staff visitor center stunning chipinque park o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>The International Society for Krishna Consciou...</td>\n",
       "      <td>international society krishna consciousness ww...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Description  \\\n",
       "119    A watering hole that attracts animals, includi...   \n",
       "9709   This museum offers a good overview of the natu...   \n",
       "11414  Formed as early as 1977 from a desire to prese...   \n",
       "4584   One of the few nature sanctuaries within day-t...   \n",
       "12856  This small plantation, which produces almost-o...   \n",
       "4622   A few partially rebuilt wall stubs are all tha...   \n",
       "16990  The Roman harbour at the base of Kaleiçi's slo...   \n",
       "9767   Was it the fall of 1966 or the winter of ’67? ...   \n",
       "12534  Staff at the visitors center of the stunning C...   \n",
       "4282   The International Society for Krishna Consciou...   \n",
       "\n",
       "                                              Lemmatized  \n",
       "119    watering hole attract animal include elephant ...  \n",
       "9709   museum offer good overview natural cultural hi...  \n",
       "11414  form early   desire preserve memory story poss...  \n",
       "4584   nature sanctuary daytrip reach mumbais city li...  \n",
       "12856  small plantation produce almostorganic shadegr...  \n",
       "4622   partially rebuild wall stub remain palace comp...  \n",
       "16990  roman harbour base kaleiçis slope antalyas lif...  \n",
       "9767   fall   winter ' haight saying go remember summ...  \n",
       "12534  staff visitor center stunning chipinque park o...  \n",
       "4282   international society krishna consciousness ww...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15937</th>\n",
       "      <td>About 5km south of Cooktown, this 47-hectare w...</td>\n",
       "      <td>south cooktown   wetland favourite birdwatch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7759</th>\n",
       "      <td>Nero had his Domus Aurea constructed after the...</td>\n",
       "      <td>nero domus aurea construct fire ad   rumour st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7950</th>\n",
       "      <td>A popular diving destination, these protected ...</td>\n",
       "      <td>popular diving destination protect water   res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>At the perennially popular Gardens there are a...</td>\n",
       "      <td>perennially popular garden actually site near ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>Exhibits in this museum include the crown and ...</td>\n",
       "      <td>exhibit museum include crown personal item dai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4463</th>\n",
       "      <td>Isa Khan was a noble of the Sher Shah era, and...</td>\n",
       "      <td>isa khan noble sher shah era grandiose afghans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17248</th>\n",
       "      <td>Old cars and horse-drawn carts are housed in t...</td>\n",
       "      <td>old car horsedrawn cart house silk factory gar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>The Five Mountains of Aso are the smaller moun...</td>\n",
       "      <td>mountain aso small mountain asosan caldera out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>Standing 14m high and weighing in at 30 tonnes...</td>\n",
       "      <td>stand   high weigh   tonne beautiful bronze st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15321</th>\n",
       "      <td>Family-owned winery producing award-winning ri...</td>\n",
       "      <td>familyowne winery produce awardwinne riesle sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Description  \\\n",
       "15937  About 5km south of Cooktown, this 47-hectare w...   \n",
       "7759   Nero had his Domus Aurea constructed after the...   \n",
       "7950   A popular diving destination, these protected ...   \n",
       "1020   At the perennially popular Gardens there are a...   \n",
       "2864   Exhibits in this museum include the crown and ...   \n",
       "4463   Isa Khan was a noble of the Sher Shah era, and...   \n",
       "17248  Old cars and horse-drawn carts are housed in t...   \n",
       "1870   The Five Mountains of Aso are the smaller moun...   \n",
       "5365   Standing 14m high and weighing in at 30 tonnes...   \n",
       "15321  Family-owned winery producing award-winning ri...   \n",
       "\n",
       "                                              Lemmatized  \n",
       "15937    south cooktown   wetland favourite birdwatch...  \n",
       "7759   nero domus aurea construct fire ad   rumour st...  \n",
       "7950   popular diving destination protect water   res...  \n",
       "1020   perennially popular garden actually site near ...  \n",
       "2864   exhibit museum include crown personal item dai...  \n",
       "4463   isa khan noble sher shah era grandiose afghans...  \n",
       "17248  old car horsedrawn cart house silk factory gar...  \n",
       "1870   mountain aso small mountain asosan caldera out...  \n",
       "5365   stand   high weigh   tonne beautiful bronze st...  \n",
       "15321  familyowne winery produce awardwinne riesle sh...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_preprocessed = preprocess_df(pd.DataFrame(X_train, columns = ['Description']), 'Lemmatized')\n",
    "X_test_preprocessed = preprocess_df(pd.DataFrame(X_test,  columns =['Description']), 'Lemmatized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list += list(string.punctuation)\n",
    "stopwords_list += ['sq', 'km', 'one','two', 'south', 'west', 'north', 'east', 'de', 'la', 'southeast', 'northeast', 'northwest', 'look', 'like', 'southwest', 'de', 'san', 'northern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data to be suitable for modeling\n",
    "vectorizer = TfidfVectorizer(analyzer='word', stop_words=stopwords_list, decode_error='ignore')\n",
    "# vectorizer = TfidfVectorizer(analyzer='word')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_preprocessed['Lemmatized'])\n",
    "X_test_tfidf = vectorizer.transform(X_test_preprocessed['Lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test):\n",
    "    y_preds_train = model.predict(X_train)\n",
    "    y_preds_test = model.predict(X_test)\n",
    "\n",
    "    print('Training Accuracy:', accuracy_score(y_train, y_preds_train))\n",
    "    print('Testing Accuracy:', accuracy_score(y_test, y_preds_test))\n",
    "    print(\"Train and Test Accuracy Difference:\", accuracy_score(y_train, y_preds_train)-accuracy_score(y_test, y_preds_test))\n",
    "    print('\\n---------------\\n')\n",
    "    print('Training F1:', f1_score(y_train, y_preds_train, average='weighted'))\n",
    "    print('Testing F1:', f1_score(y_test, y_preds_test, average='weighted'))\n",
    "    print('\\n---------------\\n')\n",
    "    print(classification_report(y_test, y_preds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MULTINOMIAL NAIVE BAYES MODEL(MNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNB Iteration One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Argentina', 'Australia', 'Brazil', 'Canada', 'Chile', 'China',\n",
       "       'Egypt', 'Fiji', 'France', 'Germany', 'India', 'Israel', 'Italy',\n",
       "       'Japan', 'Jordan', 'Kenya', 'Mexico', 'Morocco', 'New Zealand',\n",
       "       'Peru', 'South Africa', 'Thailand', 'Turkey',\n",
       "       'United Arab Emirates', 'United States'], dtype='<U20')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7425124792013311\n",
      "Testing Accuracy: 0.5234266703631827\n",
      "Train and Test Accuracy Difference: 0.21908580883814843\n",
      "\n",
      "---------------\n",
      "\n",
      "Training F1: 0.6812673313389652\n",
      "Testing F1: 0.4754250157939932\n",
      "\n",
      "---------------\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Argentina       0.00      0.00      0.00        73\n",
      "           Australia       0.38      0.71      0.49       252\n",
      "              Brazil       1.00      0.09      0.17       127\n",
      "              Canada       0.37      0.63      0.47       241\n",
      "               Chile       0.00      0.00      0.00        60\n",
      "               China       0.52      0.67      0.59       249\n",
      "               Egypt       0.94      0.16      0.28       104\n",
      "                Fiji       0.00      0.00      0.00        15\n",
      "              France       0.62      0.60      0.61       245\n",
      "             Germany       0.66      0.68      0.67       252\n",
      "               India       0.65      0.64      0.64       255\n",
      "              Israel       0.00      0.00      0.00        29\n",
      "               Italy       0.64      0.72      0.68       246\n",
      "               Japan       0.48      0.71      0.57       238\n",
      "              Jordan       0.00      0.00      0.00        29\n",
      "               Kenya       0.00      0.00      0.00        35\n",
      "              Mexico       0.51      0.68      0.58       203\n",
      "             Morocco       0.00      0.00      0.00        74\n",
      "         New Zealand       0.00      0.00      0.00        74\n",
      "                Peru       1.00      0.01      0.03        70\n",
      "        South Africa       1.00      0.06      0.11       115\n",
      "            Thailand       0.96      0.62      0.75       169\n",
      "              Turkey       0.59      0.76      0.66       188\n",
      "United Arab Emirates       0.00      0.00      0.00        24\n",
      "       United States       0.39      0.58      0.47       240\n",
      "\n",
      "            accuracy                           0.52      3607\n",
      "           macro avg       0.43      0.33      0.31      3607\n",
      "        weighted avg       0.54      0.52      0.48      3607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(nb, X_train_tfidf, X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNB Iteration Two- Using Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8264004437049363\n",
      "Testing Accuracy: 0.5389520377044635\n",
      "Train and Test Accuracy Difference: 0.2874484060004727\n",
      "\n",
      "---------------\n",
      "\n",
      "Training F1: 0.8097368278257866\n",
      "Testing F1: 0.5072964114748401\n",
      "\n",
      "---------------\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Argentina       1.00      0.03      0.05        73\n",
      "           Australia       0.40      0.71      0.51       252\n",
      "              Brazil       0.93      0.31      0.46       127\n",
      "              Canada       0.39      0.62      0.48       241\n",
      "               Chile       1.00      0.05      0.10        60\n",
      "               China       0.53      0.65      0.59       249\n",
      "               Egypt       0.89      0.46      0.61       104\n",
      "                Fiji       0.00      0.00      0.00        15\n",
      "              France       0.62      0.58      0.60       245\n",
      "             Germany       0.63      0.65      0.64       252\n",
      "               India       0.64      0.60      0.62       255\n",
      "              Israel       0.00      0.00      0.00        29\n",
      "               Italy       0.65      0.69      0.67       246\n",
      "               Japan       0.52      0.67      0.58       238\n",
      "              Jordan       0.00      0.00      0.00        29\n",
      "               Kenya       0.00      0.00      0.00        35\n",
      "              Mexico       0.49      0.67      0.57       203\n",
      "             Morocco       1.00      0.08      0.15        74\n",
      "         New Zealand       1.00      0.03      0.05        74\n",
      "                Peru       1.00      0.06      0.11        70\n",
      "        South Africa       0.81      0.23      0.35       115\n",
      "            Thailand       0.81      0.69      0.75       169\n",
      "              Turkey       0.55      0.76      0.64       188\n",
      "United Arab Emirates       0.00      0.00      0.00        24\n",
      "       United States       0.39      0.57      0.46       240\n",
      "\n",
      "            accuracy                           0.54      3607\n",
      "           macro avg       0.57      0.36      0.36      3607\n",
      "        weighted avg       0.60      0.54      0.51      3607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trying Count Vectorizer to see the difference\n",
    "# Vectorize the text data to be suitable for modeling\n",
    "vectorizer_cv = CountVectorizer(analyzer='word', stop_words=stopwords_list, decode_error='ignore')\n",
    "X_train_cv = vectorizer_cv.fit_transform(X_train_preprocessed['Lemmatized'])\n",
    "X_test_cv = vectorizer_cv.transform(X_test_preprocessed['Lemmatized'])\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_cv, y_train)\n",
    "evaluate_model(nb, X_train_cv, X_test_cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much more overfit, so we can keep working with TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNB Iteration Three- Using Class Weights to Improve Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Class Weights to improve class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8640460343871326\n",
      "Testing Accuracy: 0.5450512891599667\n",
      "Train and Test Accuracy Difference: 0.31899474522716587\n",
      "\n",
      "---------------\n",
      "\n",
      "Training F1: 0.8722675838024745\n",
      "Testing F1: 0.5710646547235012\n",
      "\n",
      "---------------\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Argentina       0.29      0.45      0.35        73\n",
      "           Australia       0.62      0.49      0.55       252\n",
      "              Brazil       0.60      0.63      0.62       127\n",
      "              Canada       0.57      0.45      0.50       241\n",
      "               Chile       0.42      0.37      0.39        60\n",
      "               China       0.69      0.54      0.61       249\n",
      "               Egypt       0.69      0.76      0.72       104\n",
      "                Fiji       0.17      0.60      0.27        15\n",
      "              France       0.75      0.51      0.60       245\n",
      "             Germany       0.75      0.51      0.61       252\n",
      "               India       0.81      0.50      0.62       255\n",
      "              Israel       0.20      0.48      0.28        29\n",
      "               Italy       0.78      0.58      0.66       246\n",
      "               Japan       0.74      0.57      0.64       238\n",
      "              Jordan       0.18      0.72      0.29        29\n",
      "               Kenya       0.13      0.57      0.21        35\n",
      "              Mexico       0.73      0.52      0.61       203\n",
      "             Morocco       0.38      0.53      0.44        74\n",
      "         New Zealand       0.22      0.45      0.30        74\n",
      "                Peru       0.39      0.53      0.45        70\n",
      "        South Africa       0.40      0.64      0.49       115\n",
      "            Thailand       0.74      0.76      0.75       169\n",
      "              Turkey       0.66      0.71      0.68       188\n",
      "United Arab Emirates       0.11      0.62      0.18        24\n",
      "       United States       0.63      0.40      0.49       240\n",
      "\n",
      "            accuracy                           0.55      3607\n",
      "           macro avg       0.51      0.56      0.49      3607\n",
      "        weighted avg       0.64      0.55      0.57      3607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                  classes=np.unique(y_train),\n",
    "                                                  y=y_train)\n",
    "weights_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "weights_dict\n",
    "\n",
    "# Use class weights dictionary to calculate sample weight (needed for MultinomialNB)\n",
    "sample_weights = y_train.map(weights_dict)\n",
    "sample_weights\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tfidf,\n",
    "       y_train,\n",
    "       sample_weight=sample_weights)\n",
    "\n",
    "evaluate_model(nb, X_train_tfidf, X_test_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy increases a bit but the model is more overfit than the previous one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling\n",
    "###  MNB Iteration Four- Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Over Sampling Training Accuracy score: 0.9340956340956341\n",
      "Random Over Sampling Testing Accuracy score: 0.5572497920709731\n",
      "Difference between Train and Test Accuracy: 0.376845842024661\n"
     ]
    }
   ],
   "source": [
    "# Using Random Oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "oversample = RandomOverSampler(sampling_strategy='not majority', random_state=42)\n",
    "\n",
    "\n",
    "processed = pd.DataFrame(X_train_preprocessed['Lemmatized'])\n",
    "X_train_res, y_train_res = oversample.fit_resample(processed, y_train)\n",
    "\n",
    "X_train_res = X_train_res.squeeze()\n",
    "\n",
    "ros_tfidf = TfidfVectorizer(analyzer='word', stop_words=stopwords_list, decode_error='ignore')\n",
    "X_train_ros = ros_tfidf.fit_transform(X_train_res)\n",
    "X_test_ros = ros_tfidf.transform(X_test_preprocessed['Lemmatized'])\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "\n",
    "model.fit(X_train_ros, y_train_res)\n",
    "\n",
    "resampled = model.predict(X_test_ros)\n",
    "train_pred= model.predict(X_train_ros)\n",
    "accuracy_score_train = accuracy_score(y_train_res, train_pred)\n",
    "accuracy_score_test = accuracy_score(y_test, resampled)\n",
    "\n",
    "\n",
    "print(\"Random Over Sampling Training Accuracy score:\", accuracy_score_train)\n",
    "print(\"Random Over Sampling Testing Accuracy score:\", accuracy_score_test)\n",
    "print(\"Difference between Train and Test Accuracy:\", accuracy_score_train-accuracy_score_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNB Iteration Five SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: Counter({'Japan': 962, 'United States': 960, 'Canada': 957, 'France': 955, 'Italy': 954, 'Germany': 948, 'Australia': 948, 'China': 947, 'India': 943, 'Mexico': 877, 'Turkey': 852, 'Thailand': 711, 'South Africa': 525, 'Brazil': 473, 'Egypt': 416, 'New Zealand': 326, 'Peru': 290, 'Argentina': 287, 'Morocco': 286, 'Chile': 259, 'Jordan': 131, 'Israel': 131, 'Kenya': 125, 'United Arab Emirates': 96, 'Fiji': 65})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "class_counts = Counter(y_train)\n",
    "print(\"Class distribution:\", class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minority classes: ['Fiji', 'United Arab Emirates']\n"
     ]
    }
   ],
   "source": [
    "majority_class_size = max(class_counts.values())\n",
    "threshold = 0.1 * majority_class_size  # Classes with <10% of the majority are minority\n",
    "minority_classes = [cls for cls, count in class_counts.items() if count < threshold]\n",
    "print(\"Minority classes:\", minority_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE Testing Accuracy score: 0.7654290480014827\n",
      "SMOTE Training Accuracy score: 0.514000554477405\n",
      "Difference between Test and Train Accuracy: 0.2514284935240777\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "vectorizer_smote = TfidfVectorizer()\n",
    "X_train_numeric = vectorizer_smote.fit_transform(X_train_preprocessed['Lemmatized'])\n",
    "X_test_numeric = vectorizer_smote.transform(X_test_preprocessed['Lemmatized'])\n",
    "# Target only minority classes for balancing\n",
    "smote = SMOTE(sampling_strategy={cls: majority_class_size for cls in minority_classes}, random_state=42)\n",
    "# processed = pd.DataFrame(X_train_preprocessed['Lemmatized'])\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_numeric, y_train)\n",
    "\n",
    "# X_train_res = X_train_res.squeeze()\n",
    "\n",
    "model22 = MultinomialNB()\n",
    "# Build a pipeline using the TF-IDF Vectorizer and Logistic Regression\n",
    "model22.fit(X_train_res, y_train_res)\n",
    "\n",
    "resampled22 = model22.predict(X_test_numeric)\n",
    "train_pred22= model22.predict(X_train_res)\n",
    "accuracy_score_train = accuracy_score(y_train_res, train_pred22)\n",
    "accuracy_score_test = accuracy_score(y_test, resampled22)\n",
    "# Verify new class distribution\n",
    "# from collections import Counter\n",
    "# print(\"New class distribution:\", Counter(y_train_res))\n",
    "print(\"SMOTE Testing Accuracy score:\", accuracy_score_train)\n",
    "print(\"SMOTE Training Accuracy score:\", accuracy_score_test)\n",
    "print(\"Difference between Test and Train Accuracy:\", accuracy_score_train- accuracy_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random oversampled model is the most overfit of all the iterations, while SMOTE is less overfit, but still doesn't perform as well as the first iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNB Iteration Six- Try Using Bi-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8517748197448697\n",
      "Testing Accuracy: 0.32242861103410037\n",
      "Train and Test Accuracy Difference: 0.5293462087107693\n",
      "\n",
      "---------------\n",
      "\n",
      "Training F1: 0.7943808600689665\n",
      "Testing F1: 0.2932248657223727\n",
      "\n",
      "---------------\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Argentina       0.00      0.00      0.00        73\n",
      "           Australia       0.30      0.44      0.35       252\n",
      "              Brazil       0.83      0.04      0.08       127\n",
      "              Canada       0.32      0.41      0.36       241\n",
      "               Chile       0.00      0.00      0.00        60\n",
      "               China       0.34      0.38      0.36       249\n",
      "               Egypt       0.67      0.02      0.04       104\n",
      "                Fiji       0.00      0.00      0.00        15\n",
      "              France       0.27      0.39      0.32       245\n",
      "             Germany       0.37      0.37      0.37       252\n",
      "               India       0.41      0.40      0.41       255\n",
      "              Israel       0.00      0.00      0.00        29\n",
      "               Italy       0.35      0.43      0.39       246\n",
      "               Japan       0.18      0.57      0.28       238\n",
      "              Jordan       0.00      0.00      0.00        29\n",
      "               Kenya       0.00      0.00      0.00        35\n",
      "              Mexico       0.38      0.39      0.38       203\n",
      "             Morocco       0.00      0.00      0.00        74\n",
      "         New Zealand       0.00      0.00      0.00        74\n",
      "                Peru       0.00      0.00      0.00        70\n",
      "        South Africa       1.00      0.05      0.10       115\n",
      "            Thailand       0.87      0.31      0.46       169\n",
      "              Turkey       0.51      0.48      0.49       188\n",
      "United Arab Emirates       0.00      0.00      0.00        24\n",
      "       United States       0.32      0.38      0.35       240\n",
      "\n",
      "            accuracy                           0.32      3607\n",
      "           macro avg       0.28      0.20      0.19      3607\n",
      "        weighted avg       0.36      0.32      0.29      3607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bigram = TfidfVectorizer(analyzer='word',\n",
    "                         stop_words=stopwords_list,\n",
    "                         decode_error='ignore',\n",
    "                         ngram_range=(2,2))\n",
    "X_train_bg = bigram.fit_transform(X_train_preprocessed['Lemmatized'])\n",
    "X_test_bg = bigram.transform(X_test_preprocessed['Lemmatized'])\n",
    "nb_bg = MultinomialNB()\n",
    "nb_bg.fit(X_train_bg,\n",
    "          y_train)\n",
    "evaluate_model(nb_bg, X_train_bg, X_test_bg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigrams improve the train accuracy but the testing accuracy is highly lowered, making the model very overift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the best model is still iteration one "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. RANDOM FOREST\n",
    "- The benefit of this is the ability to see feature importances and get more insight into how the model is working with the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word', \n",
    "                             stop_words=stopwords_list,\n",
    "                             decode_error='ignore')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_preprocessed['Lemmatized'])\n",
    "X_test_tfidf = vectorizer.transform(X_test_preprocessed['Lemmatized'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting class weight as balanced deals with class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "rf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.5012475741613529\n",
      "Train and Test Accuracy Difference: 0.4987524258386471\n",
      "\n",
      "---------------\n",
      "\n",
      "Training F1: 1.0\n",
      "Testing F1: 0.5027904614118391\n",
      "\n",
      "---------------\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Argentina       0.56      0.19      0.29        73\n",
      "           Australia       0.39      0.60      0.47       252\n",
      "              Brazil       0.82      0.54      0.65       127\n",
      "              Canada       0.36      0.45      0.40       241\n",
      "               Chile       0.68      0.22      0.33        60\n",
      "               China       0.49      0.46      0.47       249\n",
      "               Egypt       0.60      0.68      0.64       104\n",
      "                Fiji       0.70      0.47      0.56        15\n",
      "              France       0.48      0.48      0.48       245\n",
      "             Germany       0.51      0.53      0.52       252\n",
      "               India       0.58      0.53      0.55       255\n",
      "              Israel       0.69      0.31      0.43        29\n",
      "               Italy       0.63      0.49      0.55       246\n",
      "               Japan       0.44      0.56      0.49       238\n",
      "              Jordan       0.52      0.38      0.44        29\n",
      "               Kenya       0.93      0.40      0.56        35\n",
      "              Mexico       0.47      0.59      0.53       203\n",
      "             Morocco       0.97      0.38      0.54        74\n",
      "         New Zealand       0.70      0.28      0.40        74\n",
      "                Peru       0.49      0.27      0.35        70\n",
      "        South Africa       0.36      0.43      0.39       115\n",
      "            Thailand       0.83      0.63      0.72       169\n",
      "              Turkey       0.59      0.63      0.61       188\n",
      "United Arab Emirates       0.87      0.54      0.67        24\n",
      "       United States       0.36      0.47      0.41       240\n",
      "\n",
      "            accuracy                           0.50      3607\n",
      "           macro avg       0.60      0.46      0.50      3607\n",
      "        weighted avg       0.54      0.50      0.50      3607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(rf, X_train_tfidf, X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the worst performing model, with the training accuracy being one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aachen       9.905318e-06\n",
       "aah          1.342975e-06\n",
       "aalara       2.150395e-08\n",
       "aalto        1.828490e-06\n",
       "aaron        7.676560e-05\n",
       "aaronsohn    5.639301e-05\n",
       "aath         2.334608e-06\n",
       "ab           3.703046e-06\n",
       "abaca        8.201820e-05\n",
       "abad         3.222686e-05\n",
       "abancay      1.133380e-06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get feature importances\n",
    "feat_imps = pd.Series(rf.feature_importances_,\n",
    "                      index=vectorizer.get_feature_names_out())\n",
    "feat_imps[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "di         0.004140\n",
       "temple     0.003562\n",
       "museum     0.003150\n",
       "al         0.002947\n",
       "inca       0.002785\n",
       "medina     0.002723\n",
       "japan      0.002697\n",
       "build      0.002686\n",
       "brazil     0.002646\n",
       "dubai      0.002637\n",
       "tomb       0.002622\n",
       "wat        0.002556\n",
       "fiji       0.002469\n",
       "tel        0.002441\n",
       "nz         0.002377\n",
       "māori      0.002289\n",
       "park       0.002220\n",
       "palazzo    0.002170\n",
       "chile      0.002168\n",
       "mosque     0.002160\n",
       "dtype: float64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_feats = feat_imps.sort_values(ascending=False).head(20)\n",
    "top_20_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=top_20_feats, y=top_20_feats.index, palette='icefire')\n",
    "plt.title('Top 20 Features')\n",
    "plt.ylabel('Word')\n",
    "plt.xlabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This model is also overfit. Interestingly, the feature importances show a lot of country-specific words, such as Japan, Brazil, Dubai, nz, and fiji. In the future, it might be a good idea to take these kinds of words out, but for the model's use-case we can leave them in for now.\n",
    "\n",
    "\n",
    "Iteration 1 is the best model so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. GRADIENTBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost Iteration One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-7 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-7 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-7 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-7 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-7 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GradientBoostingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingClassifier(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7866749861342207\n",
      "Testing Accuracy: 0.5167729415026338\n",
      "Train and Test Accuracy Difference: 0.26990204463158696\n",
      "\n",
      "---------------\n",
      "\n",
      "Training F1: 0.804464004794689\n",
      "Testing F1: 0.5371919203376678\n",
      "\n",
      "---------------\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Argentina       0.33      0.25      0.28        73\n",
      "           Australia       0.58      0.47      0.52       252\n",
      "              Brazil       0.80      0.54      0.64       127\n",
      "              Canada       0.51      0.45      0.48       241\n",
      "               Chile       0.31      0.25      0.28        60\n",
      "               China       0.53      0.48      0.50       249\n",
      "               Egypt       0.59      0.62      0.60       104\n",
      "                Fiji       0.43      0.60      0.50        15\n",
      "              France       0.68      0.49      0.57       245\n",
      "             Germany       0.73      0.50      0.60       252\n",
      "               India       0.70      0.56      0.62       255\n",
      "              Israel       0.35      0.31      0.33        29\n",
      "               Italy       0.66      0.54      0.59       246\n",
      "               Japan       0.58      0.55      0.56       238\n",
      "              Jordan       0.36      0.28      0.31        29\n",
      "               Kenya       0.67      0.57      0.62        35\n",
      "              Mexico       0.63      0.57      0.60       203\n",
      "             Morocco       0.65      0.45      0.53        74\n",
      "         New Zealand       0.50      0.42      0.46        74\n",
      "                Peru       0.43      0.33      0.37        70\n",
      "        South Africa       0.46      0.48      0.47       115\n",
      "            Thailand       0.83      0.63      0.71       169\n",
      "              Turkey       0.72      0.62      0.67       188\n",
      "United Arab Emirates       0.61      0.58      0.60        24\n",
      "       United States       0.19      0.65      0.30       240\n",
      "\n",
      "            accuracy                           0.52      3607\n",
      "           macro avg       0.55      0.49      0.51      3607\n",
      "        weighted avg       0.59      0.52      0.54      3607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(gb, X_train_tfidf, X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this model is also overfit, it performs much better than the Random Forest, with less variation between the train and test accuracy. However, the first iteration of MNB is the best yet.\n",
    "\n",
    "We will try making some changes to the Gradient Boost model to see if it improves (using Count Vectorization, Oversampling, using bi-grams, and class weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost Iteration Two- Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7608153078202995\n",
      "Testing Accuracy: 0.5411699473246465\n",
      "Train and Test Accuracy Difference: 0.21964536049565297\n",
      "\n",
      "---------------\n",
      "\n",
      "Training F1: 0.7806536674890038\n",
      "Testing F1: 0.5665453201599471\n",
      "\n",
      "---------------\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Argentina       0.70      0.29      0.41        73\n",
      "           Australia       0.53      0.57      0.55       252\n",
      "              Brazil       0.74      0.52      0.61       127\n",
      "              Canada       0.52      0.46      0.49       241\n",
      "               Chile       0.37      0.18      0.24        60\n",
      "               China       0.58      0.48      0.53       249\n",
      "               Egypt       0.66      0.67      0.67       104\n",
      "                Fiji       0.75      0.60      0.67        15\n",
      "              France       0.67      0.54      0.60       245\n",
      "             Germany       0.82      0.54      0.65       252\n",
      "               India       0.71      0.56      0.63       255\n",
      "              Israel       0.56      0.31      0.40        29\n",
      "               Italy       0.66      0.56      0.60       246\n",
      "               Japan       0.66      0.57      0.61       238\n",
      "              Jordan       0.56      0.31      0.40        29\n",
      "               Kenya       0.71      0.57      0.63        35\n",
      "              Mexico       0.74      0.60      0.66       203\n",
      "             Morocco       0.76      0.43      0.55        74\n",
      "         New Zealand       0.65      0.42      0.51        74\n",
      "                Peru       0.64      0.40      0.49        70\n",
      "        South Africa       0.52      0.48      0.50       115\n",
      "            Thailand       0.84      0.62      0.71       169\n",
      "              Turkey       0.75      0.65      0.70       188\n",
      "United Arab Emirates       0.79      0.62      0.70        24\n",
      "       United States       0.19      0.70      0.29       240\n",
      "\n",
      "            accuracy                           0.54      3607\n",
      "           macro avg       0.64      0.51      0.55      3607\n",
      "        weighted avg       0.63      0.54      0.57      3607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trying Count Vectorizer to see the difference\n",
    "# Vectorize the text data to be suitable for modeling\n",
    "vectorizer_cv = CountVectorizer(analyzer='word', stop_words=stopwords_list, decode_error='ignore')\n",
    "X_train_cv = vectorizer_cv.fit_transform(X_train_preprocessed['Lemmatized'])\n",
    "X_test_cv = vectorizer_cv.transform(X_test_preprocessed['Lemmatized'])\n",
    "\n",
    "gb.fit(X_train_cv, y_train)\n",
    "evaluate_model(gb, X_train_cv, X_test_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy has been improved, with the difference between train and test accuracy also reducing, making this the best model so far. It also has the better f1 score(weighted to accomodate for class imbalance), which makes it have the best balance of precision and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost Iteration Three - Using Class Weights to fix Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7844564614531336\n",
      "Testing Accuracy: 0.5206542833379539\n",
      "Train and Test Accuracy Difference: 0.2638021781151797\n",
      "\n",
      "---------------\n",
      "\n",
      "Training F1: 0.80425582848918\n",
      "Testing F1: 0.5491481743066695\n",
      "\n",
      "---------------\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Argentina       0.31      0.33      0.32        73\n",
      "           Australia       0.66      0.46      0.54       252\n",
      "              Brazil       0.73      0.60      0.66       127\n",
      "              Canada       0.60      0.44      0.51       241\n",
      "               Chile       0.27      0.27      0.27        60\n",
      "               China       0.68      0.45      0.54       249\n",
      "               Egypt       0.61      0.64      0.63       104\n",
      "                Fiji       0.40      0.53      0.46        15\n",
      "              France       0.67      0.49      0.57       245\n",
      "             Germany       0.77      0.53      0.63       252\n",
      "               India       0.73      0.51      0.60       255\n",
      "              Israel       0.29      0.28      0.28        29\n",
      "               Italy       0.73      0.49      0.59       246\n",
      "               Japan       0.64      0.55      0.59       238\n",
      "              Jordan       0.32      0.59      0.41        29\n",
      "               Kenya       0.39      0.54      0.45        35\n",
      "              Mexico       0.70      0.60      0.65       203\n",
      "             Morocco       0.58      0.45      0.50        74\n",
      "         New Zealand       0.38      0.45      0.41        74\n",
      "                Peru       0.39      0.46      0.42        70\n",
      "        South Africa       0.43      0.53      0.47       115\n",
      "            Thailand       0.82      0.64      0.72       169\n",
      "              Turkey       0.82      0.66      0.73       188\n",
      "United Arab Emirates       0.50      0.67      0.57        24\n",
      "       United States       0.18      0.61      0.27       240\n",
      "\n",
      "            accuracy                           0.52      3607\n",
      "           macro avg       0.54      0.51      0.51      3607\n",
      "        weighted avg       0.62      0.52      0.55      3607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                  classes=np.unique(y_train),\n",
    "                                                  y=y_train)\n",
    "weights_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "weights_dict\n",
    "\n",
    "# Use class weights dictionary to calculate sample weight (needed for MultinomialNB)\n",
    "sample_weights = y_train.map(weights_dict)\n",
    "sample_weights\n",
    "\n",
    "gb.fit(X_train_tfidf,\n",
    "       y_train,\n",
    "       sample_weight=sample_weights)\n",
    "\n",
    "evaluate_model(gb, X_train_tfidf, X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost Iteration Four- Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Over Sampling Training Accuracy score: 0.851060291060291\n",
      "Random Over Sampling Testing Accuracy score: 0.5261990573884114\n",
      "Train and Test Accuracy Difference: 0.3248612336718796\n"
     ]
    }
   ],
   "source": [
    "# Using Random Oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "oversample = RandomOverSampler(sampling_strategy='not majority', random_state=42)\n",
    "\n",
    "\n",
    "processed = pd.DataFrame(X_train_preprocessed['Lemmatized'])\n",
    "X_train_res, y_train_res = oversample.fit_resample(processed, y_train)\n",
    "\n",
    "X_train_res = X_train_res.squeeze()\n",
    "\n",
    "ros_tfidf = TfidfVectorizer(analyzer='word', stop_words=stopwords_list, decode_error='ignore')\n",
    "X_train_ros = ros_tfidf.fit_transform(X_train_res)\n",
    "X_test_ros = ros_tfidf.transform(X_test_preprocessed['Lemmatized'])\n",
    "\n",
    "\n",
    "# model = GradientBoostingClassifier(random_state=42)\n",
    "# Build a pipeline using the TF-IDF Vectorizer and Logistic Regression\n",
    "gb.fit(X_train_ros, y_train_res)\n",
    "\n",
    "resampled = gb.predict(X_test_ros)\n",
    "train_pred= gb.predict(X_train_ros)\n",
    "accuracy_score_train = accuracy_score(y_train_res, train_pred)\n",
    "accuracy_score_test = accuracy_score(y_test, resampled)\n",
    "\n",
    "\n",
    "print(\"Random Over Sampling Training Accuracy score:\", accuracy_score_train)\n",
    "print(\"Random Over Sampling Testing Accuracy score:\", accuracy_score_test)\n",
    "print(\"Train and Test Accuracy Difference:\", accuracy_score_train - accuracy_score_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much more overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost Iteration Five- SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE Training Accuracy score: 0.8169518749613888\n",
      "SMOTE Testing Accuracy score: 0.5084557804269476\n",
      "Difference between Test and Train Accuracy: 0.30849609453444116\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "vectorizer_smote = TfidfVectorizer()\n",
    "X_train_numeric = vectorizer_smote.fit_transform(X_train_preprocessed['Lemmatized'])\n",
    "X_test_numeric = vectorizer_smote.transform(X_test_preprocessed['Lemmatized'])\n",
    "# Target only minority classes for balancing\n",
    "smote = SMOTE(sampling_strategy={cls: majority_class_size for cls in minority_classes}, random_state=42)\n",
    "\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_numeric, y_train)\n",
    "\n",
    "gb.fit(X_train_res, y_train_res)\n",
    "\n",
    "resampled = gb.predict(X_test_numeric)\n",
    "train_pred= gb.predict(X_train_res)\n",
    "accuracy_score_train = accuracy_score(y_train_res, train_pred)\n",
    "accuracy_score_test = accuracy_score(y_test, resampled)\n",
    "\n",
    "print(\"SMOTE Training Accuracy score:\", accuracy_score_train)\n",
    "print(\"SMOTE Testing Accuracy score:\", accuracy_score_test)\n",
    "print(\"Difference between Test and Train Accuracy:\", accuracy_score_train- accuracy_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not the best model. The difference is higher than the second GB iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. VECTOR CLASS (SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC Iteration One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9865501941209096\n",
      "Testing Accuracy: 0.5492098696978098\n",
      "Train and Test Accuracy Difference: 0.4373403244230998\n",
      "\n",
      "---------------\n",
      "\n",
      "Training F1: 0.9856247825588891\n",
      "Testing F1: 0.5301118056758048\n",
      "\n",
      "---------------\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Argentina       1.00      0.08      0.15        73\n",
      "           Australia       0.39      0.69      0.50       252\n",
      "              Brazil       0.92      0.38      0.54       127\n",
      "              Canada       0.42      0.64      0.50       241\n",
      "               Chile       1.00      0.05      0.10        60\n",
      "               China       0.58      0.62      0.60       249\n",
      "               Egypt       0.82      0.53      0.64       104\n",
      "                Fiji       0.00      0.00      0.00        15\n",
      "              France       0.62      0.61      0.61       245\n",
      "             Germany       0.61      0.70      0.65       252\n",
      "               India       0.62      0.63      0.62       255\n",
      "              Israel       1.00      0.03      0.07        29\n",
      "               Italy       0.70      0.63      0.66       246\n",
      "               Japan       0.53      0.66      0.59       238\n",
      "              Jordan       0.00      0.00      0.00        29\n",
      "               Kenya       1.00      0.06      0.11        35\n",
      "              Mexico       0.57      0.66      0.61       203\n",
      "             Morocco       1.00      0.19      0.32        74\n",
      "         New Zealand       1.00      0.09      0.17        74\n",
      "                Peru       0.92      0.17      0.29        70\n",
      "        South Africa       0.64      0.31      0.42       115\n",
      "            Thailand       0.93      0.59      0.72       169\n",
      "              Turkey       0.61      0.71      0.66       188\n",
      "United Arab Emirates       1.00      0.04      0.08        24\n",
      "       United States       0.34      0.61      0.44       240\n",
      "\n",
      "            accuracy                           0.55      3607\n",
      "           macro avg       0.69      0.39      0.40      3607\n",
      "        weighted avg       0.63      0.55      0.53      3607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(random_state=42, probability=True)\n",
    "svc.fit(X_train_tfidf, y_train)\n",
    "evaluate_model(svc, X_train_tfidf, X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is also very overfit and performs almost the same as the Random Forest one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC Iteration Two- Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.956946755407654\n",
      "Testing Accuracy: 0.4665927363459939\n",
      "Train and Test Accuracy Difference: 0.49035401906166004\n",
      "\n",
      "---------------\n",
      "\n",
      "Training F1: 0.9546058921480152\n",
      "Testing F1: 0.4448988373995546\n",
      "\n",
      "---------------\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Argentina       1.00      0.07      0.13        73\n",
      "           Australia       0.36      0.62      0.45       252\n",
      "              Brazil       0.89      0.31      0.47       127\n",
      "              Canada       0.35      0.53      0.42       241\n",
      "               Chile       1.00      0.02      0.03        60\n",
      "               China       0.48      0.48      0.48       249\n",
      "               Egypt       0.79      0.47      0.59       104\n",
      "                Fiji       0.00      0.00      0.00        15\n",
      "              France       0.48      0.52      0.50       245\n",
      "             Germany       0.44      0.65      0.52       252\n",
      "               India       0.51      0.56      0.53       255\n",
      "              Israel       0.00      0.00      0.00        29\n",
      "               Italy       0.65      0.48      0.55       246\n",
      "               Japan       0.46      0.58      0.51       238\n",
      "              Jordan       0.00      0.00      0.00        29\n",
      "               Kenya       1.00      0.06      0.11        35\n",
      "              Mexico       0.40      0.62      0.48       203\n",
      "             Morocco       1.00      0.12      0.22        74\n",
      "         New Zealand       1.00      0.03      0.05        74\n",
      "                Peru       0.86      0.09      0.16        70\n",
      "        South Africa       0.45      0.32      0.38       115\n",
      "            Thailand       0.91      0.52      0.66       169\n",
      "              Turkey       0.52      0.65      0.58       188\n",
      "United Arab Emirates       0.00      0.00      0.00        24\n",
      "       United States       0.35      0.44      0.39       240\n",
      "\n",
      "            accuracy                           0.47      3607\n",
      "           macro avg       0.56      0.32      0.33      3607\n",
      "        weighted avg       0.54      0.47      0.44      3607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trying Count Vectorizer to see the difference\n",
    "# Vectorize the text data to be suitable for modeling\n",
    "vectorizer_cv = CountVectorizer(analyzer='word', stop_words=stopwords_list, decode_error='ignore')\n",
    "X_train_cv = vectorizer_cv.fit_transform(X_train_preprocessed['Lemmatized'])\n",
    "X_test_cv = vectorizer_cv.transform(X_test_preprocessed['Lemmatized'])\n",
    "\n",
    "svc.fit(X_train_cv, y_train)\n",
    "evaluate_model(svc, X_train_cv, X_test_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also ver overfit and judging from the results, we will only tune the hyperparameters of MNB and GradientBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.824667221297837\n",
      "Testing Accuracy: 0.5652897144441364\n",
      "Train and Test Accuracy Difference: 0.25937750685370053\n",
      "\n",
      "---------------\n",
      "\n",
      "Training F1: 0.8072042031104955\n",
      "Testing F1: 0.5454027840479614\n",
      "\n",
      "---------------\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Argentina       0.88      0.10      0.17        73\n",
      "           Australia       0.44      0.67      0.53       252\n",
      "              Brazil       0.90      0.45      0.60       127\n",
      "              Canada       0.45      0.61      0.52       241\n",
      "               Chile       1.00      0.08      0.15        60\n",
      "               China       0.58      0.61      0.60       249\n",
      "               Egypt       0.78      0.58      0.66       104\n",
      "                Fiji       0.00      0.00      0.00        15\n",
      "              France       0.59      0.62      0.60       245\n",
      "             Germany       0.62      0.69      0.66       252\n",
      "               India       0.61      0.66      0.64       255\n",
      "              Israel       1.00      0.07      0.13        29\n",
      "               Italy       0.67      0.64      0.66       246\n",
      "               Japan       0.52      0.68      0.59       238\n",
      "              Jordan       0.00      0.00      0.00        29\n",
      "               Kenya       1.00      0.09      0.16        35\n",
      "              Mexico       0.52      0.68      0.59       203\n",
      "             Morocco       1.00      0.19      0.32        74\n",
      "         New Zealand       1.00      0.14      0.24        74\n",
      "                Peru       0.87      0.19      0.31        70\n",
      "        South Africa       0.60      0.43      0.50       115\n",
      "            Thailand       0.84      0.69      0.76       169\n",
      "              Turkey       0.58      0.72      0.64       188\n",
      "United Arab Emirates       1.00      0.04      0.08        24\n",
      "       United States       0.40      0.59      0.48       240\n",
      "\n",
      "            accuracy                           0.57      3607\n",
      "           macro avg       0.67      0.41      0.42      3607\n",
      "        weighted avg       0.62      0.57      0.55      3607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(X_train_tfidf, y_train)\n",
    "evaluate_model(lr, X_train_tfidf, X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not as bad as Random Forest and SVC. Let's see if count vectorization, which improved on the GradientBoost model, improves this one too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Iteration Two- Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9979894620077648\n",
      "Testing Accuracy: 0.572775159412254\n",
      "Train and Test Accuracy Difference: 0.42521430259551085\n",
      "\n",
      "---------------\n",
      "\n",
      "Training F1: 0.9979881489190341\n",
      "Testing F1: 0.5654514593642909\n",
      "\n",
      "---------------\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Argentina       0.53      0.25      0.34        73\n",
      "           Australia       0.49      0.58      0.53       252\n",
      "              Brazil       0.74      0.53      0.62       127\n",
      "              Canada       0.47      0.56      0.51       241\n",
      "               Chile       0.58      0.18      0.28        60\n",
      "               China       0.58      0.60      0.59       249\n",
      "               Egypt       0.78      0.67      0.72       104\n",
      "                Fiji       1.00      0.20      0.33        15\n",
      "              France       0.59      0.58      0.59       245\n",
      "             Germany       0.59      0.65      0.62       252\n",
      "               India       0.64      0.64      0.64       255\n",
      "              Israel       0.86      0.21      0.33        29\n",
      "               Italy       0.66      0.63      0.65       246\n",
      "               Japan       0.54      0.67      0.59       238\n",
      "              Jordan       0.46      0.21      0.29        29\n",
      "               Kenya       0.64      0.26      0.37        35\n",
      "              Mexico       0.54      0.63      0.58       203\n",
      "             Morocco       0.66      0.28      0.40        74\n",
      "         New Zealand       0.55      0.31      0.40        74\n",
      "                Peru       0.62      0.34      0.44        70\n",
      "        South Africa       0.46      0.56      0.50       115\n",
      "            Thailand       0.79      0.73      0.76       169\n",
      "              Turkey       0.60      0.72      0.66       188\n",
      "United Arab Emirates       0.67      0.08      0.15        24\n",
      "       United States       0.46      0.57      0.51       240\n",
      "\n",
      "            accuracy                           0.57      3607\n",
      "           macro avg       0.62      0.47      0.50      3607\n",
      "        weighted avg       0.59      0.57      0.57      3607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trying Count Vectorizer to see the difference\n",
    "# Vectorize the text data to be suitable for modeling\n",
    "vectorizer_cv = CountVectorizer(analyzer='word', stop_words=stopwords_list, decode_error='ignore')\n",
    "X_train_cv = vectorizer_cv.fit_transform(X_train_preprocessed['Lemmatized'])\n",
    "X_test_cv = vectorizer_cv.transform(X_test_preprocessed['Lemmatized'])\n",
    "\n",
    "lr.fit(X_train_cv, y_train)\n",
    "evaluate_model(lr, X_train_cv, X_test_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the test accuracy improves a bit, the model is very overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.3834211255891322\n",
      "Train and Test Accuracy Difference: 0.6165788744108678\n",
      "\n",
      "---------------\n",
      "\n",
      "Training F1: 1.0\n",
      "Testing F1: 0.38239108000085115\n",
      "\n",
      "---------------\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Argentina       0.23      0.18      0.20        73\n",
      "           Australia       0.36      0.40      0.38       252\n",
      "              Brazil       0.62      0.44      0.52       127\n",
      "              Canada       0.37      0.36      0.37       241\n",
      "               Chile       0.33      0.15      0.21        60\n",
      "               China       0.35      0.36      0.36       249\n",
      "               Egypt       0.51      0.53      0.52       104\n",
      "                Fiji       0.50      0.13      0.21        15\n",
      "              France       0.41      0.40      0.41       245\n",
      "             Germany       0.35      0.35      0.35       252\n",
      "               India       0.45      0.41      0.43       255\n",
      "              Israel       0.22      0.14      0.17        29\n",
      "               Italy       0.43      0.40      0.42       246\n",
      "               Japan       0.39      0.46      0.42       238\n",
      "              Jordan       0.39      0.24      0.30        29\n",
      "               Kenya       0.12      0.09      0.10        35\n",
      "              Mexico       0.36      0.45      0.40       203\n",
      "             Morocco       0.33      0.26      0.29        74\n",
      "         New Zealand       0.26      0.23      0.24        74\n",
      "                Peru       0.20      0.20      0.20        70\n",
      "        South Africa       0.25      0.39      0.30       115\n",
      "            Thailand       0.65      0.56      0.60       169\n",
      "              Turkey       0.41      0.48      0.44       188\n",
      "United Arab Emirates       0.33      0.25      0.29        24\n",
      "       United States       0.32      0.33      0.32       240\n",
      "\n",
      "            accuracy                           0.38      3607\n",
      "           macro avg       0.37      0.33      0.34      3607\n",
      "        weighted avg       0.39      0.38      0.38      3607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state= 42)\n",
    "dt.fit(X_train_tfidf, y_train)\n",
    "evaluate_model(dt, X_train_tfidf, X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Tree Model is very overfit, with a training accuracy of 1.0. Clearly, the Random Forest and Decision Tree which are tree-based models are overfitting a lot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. KNEIGHBORS CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.6956461453133667\n",
      "Testing Accuracy: 0.4835042971998891\n",
      "Train and Test Accuracy Difference: 0.21214184811347758\n",
      "\n",
      "---------------\n",
      "\n",
      "Training F1: 0.6975934842058451\n",
      "Testing F1: 0.4858197764896338\n",
      "\n",
      "---------------\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Argentina       0.19      0.33      0.24        73\n",
      "           Australia       0.31      0.58      0.40       252\n",
      "              Brazil       0.36      0.54      0.43       127\n",
      "              Canada       0.34      0.52      0.41       241\n",
      "               Chile       0.25      0.20      0.22        60\n",
      "               China       0.44      0.53      0.48       249\n",
      "               Egypt       0.58      0.66      0.62       104\n",
      "                Fiji       0.31      0.27      0.29        15\n",
      "              France       0.52      0.51      0.51       245\n",
      "             Germany       0.56      0.47      0.51       252\n",
      "               India       0.62      0.51      0.56       255\n",
      "              Israel       0.78      0.24      0.37        29\n",
      "               Italy       0.70      0.44      0.54       246\n",
      "               Japan       0.66      0.56      0.61       238\n",
      "              Jordan       0.79      0.38      0.51        29\n",
      "               Kenya       0.71      0.29      0.41        35\n",
      "              Mexico       0.50      0.56      0.53       203\n",
      "             Morocco       0.84      0.28      0.42        74\n",
      "         New Zealand       0.60      0.20      0.30        74\n",
      "                Peru       0.48      0.33      0.39        70\n",
      "        South Africa       0.49      0.37      0.42       115\n",
      "            Thailand       0.67      0.65      0.66       169\n",
      "              Turkey       0.65      0.66      0.65       188\n",
      "United Arab Emirates       0.62      0.21      0.31        24\n",
      "       United States       0.47      0.28      0.35       240\n",
      "\n",
      "            accuracy                           0.48      3607\n",
      "           macro avg       0.54      0.42      0.45      3607\n",
      "        weighted avg       0.53      0.48      0.49      3607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn= KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
    "knn.fit(X_train_tfidf, y_train)\n",
    "evaluate_model(knn, X_train_tfidf, X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this model is also less overfit (0.22 difference between train and test accuracies), its accuracy is lower than the second iteration of GradientBoost, making GradientBoost still the best option. Its F1 score is also much lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.3103854686633389\n",
      "Testing Accuracy: 0.09453839756029941\n",
      "Train and Test Accuracy Difference: 0.21584707110303947\n",
      "\n",
      "---------------\n",
      "\n",
      "Training F1: 0.3038122065452747\n",
      "Testing F1: 0.06070338989647092\n",
      "\n",
      "---------------\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Argentina       0.15      0.03      0.05        73\n",
      "           Australia       0.08      0.56      0.14       252\n",
      "              Brazil       0.08      0.02      0.04       127\n",
      "              Canada       0.16      0.02      0.04       241\n",
      "               Chile       0.33      0.02      0.03        60\n",
      "               China       0.13      0.03      0.05       249\n",
      "               Egypt       1.00      0.04      0.07       104\n",
      "                Fiji       0.00      0.00      0.00        15\n",
      "              France       0.25      0.01      0.02       245\n",
      "             Germany       0.25      0.01      0.02       252\n",
      "               India       0.47      0.03      0.06       255\n",
      "              Israel       0.00      0.00      0.00        29\n",
      "               Italy       0.17      0.00      0.01       246\n",
      "               Japan       0.33      0.01      0.02       238\n",
      "              Jordan       1.00      0.03      0.07        29\n",
      "               Kenya       0.00      0.00      0.00        35\n",
      "              Mexico       0.08      0.40      0.13       203\n",
      "             Morocco       0.00      0.00      0.00        74\n",
      "         New Zealand       0.24      0.05      0.09        74\n",
      "                Peru       0.03      0.11      0.05        70\n",
      "        South Africa       0.15      0.08      0.10       115\n",
      "            Thailand       0.16      0.23      0.19       169\n",
      "              Turkey       0.47      0.09      0.14       188\n",
      "United Arab Emirates       0.00      0.00      0.00        24\n",
      "       United States       0.44      0.02      0.03       240\n",
      "\n",
      "            accuracy                           0.09      3607\n",
      "           macro avg       0.24      0.07      0.05      3607\n",
      "        weighted avg       0.25      0.09      0.06      3607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trying Count Vectorizer to see the difference\n",
    "# Vectorize the text data to be suitable for modeling\n",
    "vectorizer_cv = CountVectorizer(analyzer='word', stop_words=stopwords_list, decode_error='ignore')\n",
    "X_train_cv = vectorizer_cv.fit_transform(X_train_preprocessed['Lemmatized'])\n",
    "X_test_cv = vectorizer_cv.transform(X_test_preprocessed['Lemmatized'])\n",
    "\n",
    "knn.fit(X_train_cv, y_train)\n",
    "evaluate_model(knn, X_train_cv, X_test_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both accuracies are very low and the model performs very poorly. This is the worst performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on all these results, we will only try to tune the MNB and GradientBoost Models.\n",
    "Scoring will be **weighted**- Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance, which we have in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning- Tuning MNB and GradientBoost Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out because it takes too long to run. Obtained parameters have been given below\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# params_mn = {\n",
    "#     'alpha':[.001, .01, .05, .1, .2, .4, .6, .8, 1],\n",
    "#     'fit_prior': [True, False]\n",
    "# }\n",
    "# nb_gridsearch = GridSearchCV(estimator = nb, param_grid=params_mn, cv = 5, scoring='f1_weighted')\n",
    "# nb_gridsearch.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Report best score and parameters\n",
    "# print(f\"Best score: {nb_gridsearch.best_score_:.3f}\")\n",
    "# print(f\"Best parameters: {nb_gridsearch.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's refit it again with the new parameters and get the new test and train accuracies- Best parameters: {'alpha': 0.05, 'fit_prior': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9884914032168608\n",
      "Testing Accuracy: 0.6165788744108678\n",
      "Train and Test Accuracy Difference: 0.371912528805993\n",
      "\n",
      "---------------\n",
      "\n",
      "Training F1: 0.9884992190487341\n",
      "Testing F1: 0.6128367682930148\n",
      "\n",
      "---------------\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Argentina       0.47      0.33      0.39        73\n",
      "           Australia       0.51      0.63      0.56       252\n",
      "              Brazil       0.73      0.63      0.68       127\n",
      "              Canada       0.47      0.59      0.52       241\n",
      "               Chile       0.67      0.27      0.38        60\n",
      "               China       0.65      0.66      0.66       249\n",
      "               Egypt       0.78      0.73      0.75       104\n",
      "                Fiji       1.00      0.27      0.42        15\n",
      "              France       0.63      0.61      0.62       245\n",
      "             Germany       0.69      0.71      0.70       252\n",
      "               India       0.73      0.64      0.68       255\n",
      "              Israel       0.58      0.24      0.34        29\n",
      "               Italy       0.76      0.70      0.73       246\n",
      "               Japan       0.67      0.70      0.69       238\n",
      "              Jordan       0.69      0.31      0.43        29\n",
      "               Kenya       0.61      0.31      0.42        35\n",
      "              Mexico       0.62      0.72      0.67       203\n",
      "             Morocco       0.66      0.45      0.53        74\n",
      "         New Zealand       0.42      0.34      0.37        74\n",
      "                Peru       0.63      0.39      0.48        70\n",
      "        South Africa       0.47      0.53      0.50       115\n",
      "            Thailand       0.72      0.80      0.76       169\n",
      "              Turkey       0.65      0.76      0.70       188\n",
      "United Arab Emirates       0.56      0.21      0.30        24\n",
      "       United States       0.46      0.54      0.50       240\n",
      "\n",
      "            accuracy                           0.62      3607\n",
      "           macro avg       0.63      0.52      0.55      3607\n",
      "        weighted avg       0.63      0.62      0.61      3607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB(alpha=0.05, fit_prior=False)\n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "evaluate_model(nb, X_train_tfidf, X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the test accuracy increases, the model is now very overfit compared to the first iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning GradientBoost Iteration Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out because it was taking too long to run, but the best parameters were obtained as indicated in the markdown below.\n",
    "# Since we were only trying to tune the number of estimators, we will try with 50 below and see the difference\n",
    "# param_grid_gb = {\n",
    "#     'n_estimators': [50, 100]\n",
    "# }\n",
    "# grid_search_gb =GridSearchCV(estimator = gb,param_grid=param_grid_gb, scoring='f1_weighted' )\n",
    "# grid_search_gb.fit(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.6460759844703272\n",
      "Testing Accuracy: 0.4976434710285556\n",
      "Train and Test Accuracy Difference: 0.1484325134417716\n",
      "\n",
      "---------------\n",
      "\n",
      "Training F1: 0.6856463180001228\n",
      "Testing F1: 0.5371876347599285\n",
      "\n",
      "---------------\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Argentina       0.74      0.27      0.40        73\n",
      "           Australia       0.60      0.48      0.53       252\n",
      "              Brazil       0.88      0.48      0.62       127\n",
      "              Canada       0.50      0.45      0.47       241\n",
      "               Chile       0.42      0.18      0.26        60\n",
      "               China       0.56      0.44      0.49       249\n",
      "               Egypt       0.66      0.62      0.64       104\n",
      "                Fiji       0.60      0.60      0.60        15\n",
      "              France       0.65      0.47      0.54       245\n",
      "             Germany       0.82      0.48      0.60       252\n",
      "               India       0.68      0.55      0.61       255\n",
      "              Israel       0.53      0.31      0.39        29\n",
      "               Italy       0.64      0.52      0.57       246\n",
      "               Japan       0.71      0.45      0.55       238\n",
      "              Jordan       0.39      0.31      0.35        29\n",
      "               Kenya       0.71      0.57      0.63        35\n",
      "              Mexico       0.71      0.51      0.60       203\n",
      "             Morocco       0.79      0.42      0.55        74\n",
      "         New Zealand       0.81      0.41      0.54        74\n",
      "                Peru       0.62      0.37      0.46        70\n",
      "        South Africa       0.50      0.44      0.47       115\n",
      "            Thailand       0.86      0.60      0.70       169\n",
      "              Turkey       0.86      0.57      0.68       188\n",
      "United Arab Emirates       0.75      0.62      0.68        24\n",
      "       United States       0.15      0.74      0.25       240\n",
      "\n",
      "            accuracy                           0.50      3607\n",
      "           macro avg       0.65      0.47      0.53      3607\n",
      "        weighted avg       0.64      0.50      0.54      3607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_50 = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
    "gb_50.fit(X_train_cv, y_train)\n",
    "evaluate_model(gb_50, X_train_cv, X_test_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the model is less overfit, the accuracies have reduced by a lot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying with 200 n_estimators below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8598863006100943\n",
      "Testing Accuracy: 0.5719434433046854\n",
      "Train and Test Accuracy Difference: 0.2879428573054089\n",
      "\n",
      "---------------\n",
      "\n",
      "Training F1: 0.8680622642837107\n",
      "Testing F1: 0.5876688345753117\n",
      "\n",
      "---------------\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Argentina       0.70      0.29      0.41        73\n",
      "           Australia       0.52      0.60      0.55       252\n",
      "              Brazil       0.76      0.53      0.62       127\n",
      "              Canada       0.53      0.54      0.54       241\n",
      "               Chile       0.34      0.20      0.25        60\n",
      "               China       0.61      0.56      0.58       249\n",
      "               Egypt       0.71      0.68      0.70       104\n",
      "                Fiji       0.75      0.60      0.67        15\n",
      "              France       0.66      0.57      0.61       245\n",
      "             Germany       0.80      0.58      0.67       252\n",
      "               India       0.73      0.60      0.66       255\n",
      "              Israel       0.56      0.31      0.40        29\n",
      "               Italy       0.69      0.58      0.63       246\n",
      "               Japan       0.63      0.62      0.63       238\n",
      "              Jordan       0.57      0.28      0.37        29\n",
      "               Kenya       0.71      0.57      0.63        35\n",
      "              Mexico       0.71      0.64      0.67       203\n",
      "             Morocco       0.76      0.42      0.54        74\n",
      "         New Zealand       0.60      0.42      0.49        74\n",
      "                Peru       0.61      0.39      0.47        70\n",
      "        South Africa       0.54      0.50      0.52       115\n",
      "            Thailand       0.82      0.68      0.74       169\n",
      "              Turkey       0.73      0.69      0.71       188\n",
      "United Arab Emirates       0.79      0.62      0.70        24\n",
      "       United States       0.22      0.66      0.34       240\n",
      "\n",
      "            accuracy                           0.57      3607\n",
      "           macro avg       0.64      0.53      0.56      3607\n",
      "        weighted avg       0.63      0.57      0.59      3607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_200 = GradientBoostingClassifier(n_estimators=200, random_state=42)\n",
    "gb_200.fit(X_train_cv, y_train)\n",
    "evaluate_model(gb_200, X_train_cv, X_test_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracies have increased but the model is more overfit. Ultimately, the best performing model is the second iteration of the GradientBoost model- With Count Vectorization.<br>\n",
    "**Reasoning:**\n",
    "- The model achieves the best balance between test and train accuracy, without compromising on the values themselves.\n",
    "- Compared to the other contender(the first iteration of MNB), it has the best F1 score, which means that it has the best balance of precision and accuracy, which is important for the destination suggestions and predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final check, let's remove the country names by adding them to the stopwords list to see how this impacts the model. The precense of these words in the top feature names means that they could be making the models biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stopwords = stopwords_list + ['Argentina', 'Australia', 'Brazil', 'Canada', 'Chile', 'China',\n",
    "       'Egypt', 'Fiji', 'France', 'Germany', 'India', 'Israel', 'Italy',\n",
    "       'Japan', 'Jordan', 'Kenya', 'Mexico', 'Morocco', 'New Zealand',\n",
    "       'Peru', 'South Africa', 'Thailand', 'Turkey',\n",
    "       'United Arab Emirates', 'United States']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7608153078202995\n",
      "Testing Accuracy: 0.5411699473246465\n",
      "Train and Test Accuracy Difference: 0.21964536049565297\n",
      "\n",
      "---------------\n",
      "\n",
      "Training F1: 0.7806536674890038\n",
      "Testing F1: 0.5665453201599471\n",
      "\n",
      "---------------\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Argentina       0.70      0.29      0.41        73\n",
      "           Australia       0.53      0.57      0.55       252\n",
      "              Brazil       0.74      0.52      0.61       127\n",
      "              Canada       0.52      0.46      0.49       241\n",
      "               Chile       0.37      0.18      0.24        60\n",
      "               China       0.58      0.48      0.53       249\n",
      "               Egypt       0.66      0.67      0.67       104\n",
      "                Fiji       0.75      0.60      0.67        15\n",
      "              France       0.67      0.54      0.60       245\n",
      "             Germany       0.82      0.54      0.65       252\n",
      "               India       0.71      0.56      0.63       255\n",
      "              Israel       0.56      0.31      0.40        29\n",
      "               Italy       0.66      0.56      0.60       246\n",
      "               Japan       0.66      0.57      0.61       238\n",
      "              Jordan       0.56      0.31      0.40        29\n",
      "               Kenya       0.71      0.57      0.63        35\n",
      "              Mexico       0.74      0.60      0.66       203\n",
      "             Morocco       0.76      0.43      0.55        74\n",
      "         New Zealand       0.65      0.42      0.51        74\n",
      "                Peru       0.64      0.40      0.49        70\n",
      "        South Africa       0.52      0.48      0.50       115\n",
      "            Thailand       0.84      0.62      0.71       169\n",
      "              Turkey       0.75      0.65      0.70       188\n",
      "United Arab Emirates       0.79      0.62      0.70        24\n",
      "       United States       0.19      0.70      0.29       240\n",
      "\n",
      "            accuracy                           0.54      3607\n",
      "           macro avg       0.64      0.51      0.55      3607\n",
      "        weighted avg       0.63      0.54      0.57      3607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "vectorizer_cv = CountVectorizer(analyzer='word', stop_words=new_stopwords, decode_error='ignore')\n",
    "X_train_cv = vectorizer_cv.fit_transform(X_train_preprocessed['Lemmatized'])\n",
    "X_test_cv = vectorizer_cv.transform(X_test_preprocessed['Lemmatized'])\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb.fit(X_train_cv, y_train)\n",
    "evaluate_model(gb, X_train_cv, X_test_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not make a difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST OUT MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, this model should tell people where they should travel based on what they want to do when on vacation. Let's take a look at some of the sample predictions this model would give them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Input raw text.\n",
    "    Return preprocessed text.\n",
    "    \"\"\"\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    preprocessed = nlp(text)\n",
    "\n",
    "    preprocessed = text.lower()\n",
    "    preprocessed = re.sub('[%s]' % re.escape(string.punctuation), '', preprocessed)\n",
    "    preprocessed = re.sub('\\w*\\d\\w*','', preprocessed)\n",
    "\n",
    "    \n",
    "    return [preprocessed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_final = CountVectorizer(analyzer='word', stop_words=new_stopwords, decode_error='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = vectorizer_final.fit_transform(X_train_preprocessed['Lemmatized'])\n",
    "X_test_final = vectorizer_final.transform(X_test_preprocessed['Lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-8 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-8 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-8 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-8 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-8 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GradientBoostingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingClassifier(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = GradientBoostingClassifier(random_state=42)\n",
    "final_model.fit(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_test = final_model.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5411699473246465"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best place for hiking and snorkeling']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text = 'Best place for hiking and snorkeling'\n",
    "preprocessed_text = preprocess_text(raw_text)\n",
    "preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mexico'], dtype=object)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.predict(vectorizer_final.transform(preprocessed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['where can i go hiking and swimming in the ocean']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Australia'], dtype=object)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed2 = preprocess_text('Where can I go hiking and swimming in the ocean?')\n",
    "print(preprocessed2)\n",
    "final_model.predict(vectorizer_final.transform(preprocessed2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['which is the best place to do wine tastings long walks on the beach and dinners on the beach']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['South Africa'], dtype=object)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed3 = preprocess_text('Which is the best place to do Wine tastings, long walks on the beach and dinners on the beach')\n",
    "print(preprocessed3)\n",
    "final_model.predict(vectorizer_final.transform(preprocessed3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['where can i do yoga on the beach']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['United States'], dtype=object)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed4 = preprocess_text('Where can I do yoga on the beach?')\n",
    "print(preprocessed4)\n",
    "final_model.predict(vectorizer_final.transform(preprocessed4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['where can i visit historical museums']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['United States'], dtype=object)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed5 = preprocess_text('Where can I visit historical museums?')\n",
    "print(preprocessed5)\n",
    "final_model.predict(vectorizer_final.transform(preprocessed5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['where can i see alpine meadows and glaciers']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Chile'], dtype=object)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed6 = preprocess_text('Where can I see alpine meadows and glaciers?')\n",
    "print(preprocessed6)\n",
    "final_model.predict(vectorizer_final.transform(preprocessed6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['where can i see alpine meadows rivers lakes and glaciers']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Chile'], dtype=object)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed7 = preprocess_text('Where can I see alpine meadows, rivers, lakes, and glaciers?')\n",
    "print(preprocessed7)\n",
    "final_model.predict(vectorizer_final.transform(preprocessed7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Comparison of The Tested Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will visualize the Train Accuracy, Test Accuracy, Difference between accuracies, and F1 Scores of the best performing iterations of all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracies Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNB</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GB</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DT</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Train Accuracy  Test Accuracy  F1 Score  Accuracies Difference\n",
       "0   MNB            0.74           0.52      0.48                   0.22\n",
       "1    RF            1.00           0.51      0.51                   0.49\n",
       "2    GB            0.76           0.54      0.57                   0.22\n",
       "3   SVC            0.99           0.55      0.44                   0.44\n",
       "4    LR            0.82           0.57      0.54                   0.25\n",
       "5    DT            1.00           0.38      0.38                   0.62\n",
       "6   KNN            0.70           0.48      0.49                   0.22"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "models = ['MNB', 'RF', 'GB', 'SVC', 'LR', 'DT', 'KNN']\n",
    "train_accuracies = [0.74, 1.00, 0.76, 0.99, 0.82, 1.00, 0.70]\n",
    "test_accuracies= [0.52, 0.51, 0.54, 0.55, 0.57, 0.38, 0.48]\n",
    "\n",
    "f1_scores= [0.48, 0.51, 0.57, 0.44, 0.54, 0.38, 0.49 ]\n",
    "models_comparison =  pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Train Accuracy': train_accuracies,\n",
    "    'Test Accuracy': test_accuracies,\n",
    "    'F1 Score': f1_scores\n",
    "})\n",
    "models_comparison['Accuracies Difference'] = models_comparison['Train Accuracy']- models_comparison['Test Accuracy']\n",
    "models_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracies and F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a mapping between abbreviations and full names\n",
    "model_full_names = {\n",
    "    'MNB': 'Multinomial Naive Bayes',\n",
    "    'RF': 'Random Forest',\n",
    "    'GB': 'Gradient Boost',\n",
    "    'SVC': 'Support Vector Classifier',\n",
    "    'LR': 'Logistic Regression',\n",
    "    'DT': 'Decision Tree',\n",
    "    'KNN': 'K-Nearest Neighbors'\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(10, 4))\n",
    "\n",
    "# Plot 1: Train and Test Accuracies Differences\n",
    "sns.barplot(x='Model', y='Accuracies Difference', ax=ax[0], data=models_comparison, palette='icefire')\n",
    "ax[0].set_title('Train and Test Accuracies Differences')\n",
    "\n",
    "# Plot 2: F1 Scores\n",
    "sns.barplot(x='Model', y='F1 Score', ax=ax[1], data=models_comparison, palette='icefire')\n",
    "ax[1].set_title('Model F1 Scores')\n",
    "\n",
    "# Add a legend with full model names\n",
    "handles = [\n",
    "    plt.Line2D([0], [0], color=sns.color_palette('icefire', len(models_comparison))[_], marker='o', linestyle='', label=model_full_names[abbr])\n",
    "    for _, abbr in enumerate(models_comparison['Model'].unique())\n",
    "]\n",
    "\n",
    "fig.legend(handles=handles, title=\"Models\", bbox_to_anchor=(1.05, 0.5), loc='center left', frameon=True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model is the GradientBoost Classifier, which can predict a destination with 54% accuracy and a 57% F1 score (Iteration two of the GB Classifier in this notebook with Count Vectorization). The higher the F1 score, the better is the performance of our model, and this model has the best F1 score, and the least variation between the test and train accuracies, making it the least overfit. It will generalize best to unseen data.\n",
    "\n",
    "The data put into this model is lowercased, punctuations removed, lemmatized, and with stop words removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fit, Evaluation, and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy and F1 score were used to evaluate model performance. With 25 target classes, accuracy is critical to gauge overall correctness. However, due to class imbalance, the weighted F1 score was prioritized to account for false positives and false negatives, offering a balanced perspective between precision and recall.\n",
    "\n",
    "The selected model demonstrated one of the highest accuracies while avoiding overfitting, making it a strong candidate compared to other models. Although it performs well in predicting across 25 classes, further improvement is needed through additional data and fine-tuning.\n",
    "\n",
    "Final Model Performance:\n",
    "\n",
    "- Training Accuracy: 0.76, F1 Score: 0.78\n",
    "- Testing Accuracy: 0.54, F1 Score: 0.57\n",
    "\n",
    "Multiple iterations were conducted with various models, including Multinomial Naive Bayes (MNB), Random Forest, Gradient Boosting, Decision Trees, Logistic Regression, Support Vector Classifier (SVC), and K-Nearest Neighbors (KNN). Key efforts included:\n",
    "\n",
    "- Addressing class imbalance using oversampling techniques (Random Oversampling, SMOTE) and class weights.\n",
    "- Exploring TF-IDF vectorization versus CountVectorization.\n",
    "- Including bi-grams for feature engineering.\n",
    "- Adding country names to the stop word list.\n",
    "- Hyperparameter tuning to optimize model performance.\n",
    "\n",
    "These iterative approaches highlight the model's potential while identifying areas for further development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations\n",
    "- **Travel Enthusiasts/Travelers**: The interactive dashboard created offers an opportunity for travel enthusiasts to shorten the time involved in decision making based on their likes and interests. Through this, they could get an opportunity to explore their best interests despite having limited time. The product simplifies their search for an appropriate travel destination.\n",
    "\n",
    "- **Travel platforms and websites**: :Travel platforms should broaden their content to include a wider range of countries, particularly those currently underrepresented. This approach would offer more balanced visibility to diverse regions with unique attractions.\n",
    "\n",
    "\n",
    "- **Destination Marketers:** \n",
    "> - The project highlights the limitations in vocabulary used to descibe top attractions in countries such as museum, art gallery, unesco world heritage, which could point to a bias in the marketing of top attractions, focusing on specific types of attractions only. Destination marketers can apply this knowledge and integrate a broader marketing approach that could highlight the rare but unique destinations to present a more balanced image.\n",
    "\n",
    ">  - Enhance Kenyan Destination Marketing:Promote Kenya's coastal beaches, urban culture, and adventure sports alongside its wildlife offerings. Use comprehensive language in promotional materials to portray Kenya as a multi-faceted destination, attracting a broader range of tourists.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Implementation\n",
    "1. Refine Machine Learning Model:Improve the text classification model's accuracy, especially for underrepresented countries. Steps include:\n",
    "    - *Balance the dataset*: Ensure even distribution of countries in the training data.\n",
    "    - *Expand feature set*: Incorporate advanced text processing techniques to capture nuanced descriptors.\n",
    "    - *Tune the model*: Experiment with various machine learning models and hyperparameters.\n",
    "    - *Implement user feedback*: Incorporate a mechanism for users to rate and refine suggestions, enabling continuous improvement.\n",
    "\n",
    "2. Integrate with Travel Platforms:Implement the machine learning model as a personalized recommendation tool on travel websites and apps. This AI-driven feature could help users discover new destinations based on their preferences.\n",
    "\n",
    "3. Data Expansion and Enrichment:\n",
    "    - *Incorporate Additional Data*: Include diverse travel websites, lesser-known attractions, and user-generated content.\n",
    "    - *Geospatial Data*: Integrate location data to enhance recommendation accuracy based on destination types.\n",
    "4. Advanced NLP Techniques:\n",
    "    - *Deep Learning Models*: Utilize transformers (e.g., BERT, GPT) for improved text classification accuracy.\n",
    "    - *Topic Modeling*: Apply techniques like Latent Dirichlet Allocation to uncover hidden topics in travel descriptions.\n",
    "5. User Profiling and Personalization: \n",
    "    - *User Profiles*: Create profiles based on travel history and preferences for personalized recommendations.\n",
    "    - *Adaptive Recommendations*: Refine suggestions based on user interactions and feedback.\n",
    "6. Mobile App Development:\n",
    "    - Create an app offering real-time recommendations based on user preferences, travel deals, and seasonal factors.\n",
    "    - Incorporate user feedback for continuous model improvement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create A Pipeline for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use OOP to get preprocessing steps into a pipeline\n",
    "class PreprocessText(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self = self\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, **transform_params):\n",
    "        try:\n",
    "            X = pd.DataFrame(X, columns=['Description'])\n",
    "            X['Cleaned'] = X['Description'].apply(lambda x: x.lower())\n",
    "            X['Cleaned'] = X['Cleaned'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))\n",
    "            X['Cleaned'] = X['Cleaned'].apply(lambda x: re.sub('\\w*\\d\\w*','', x))\n",
    "            X['Lemmatized'] = X['Cleaned'].apply(lambda x: ' '.join(\n",
    "                                    [token.lemma_ for token in list(lemmatized(x)) if (token.is_stop==False)]))\n",
    "            \n",
    "            X = X['Lemmatized']\n",
    "        except:\n",
    "            pass\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119      watering hole attract animal include elephant ...\n",
       "9709     museum offer good overview natural cultural hi...\n",
       "11414    form early   desire preserve memory story poss...\n",
       "4584     nature sanctuary daytrip reach mumbais city li...\n",
       "12856    small plantation produce almostorganic shadegr...\n",
       "                               ...                        \n",
       "11290    build   shimmer tintopped house worship old ch...\n",
       "11972      brother oscar marius dufresne commission bea...\n",
       "5396     ao wai lovely beach far remove reality   ao thian\n",
       "860      amenemhat   governor oryx tomb large possibly ...\n",
       "15804      south peppermint bay stop foodie grandvewe c...\n",
       "Name: Lemmatized, Length: 14424, dtype: object"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test preprocessing class\n",
    "prep = PreprocessText()\n",
    "prep.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "                ('TextPreprocessor', PreprocessText()),\n",
    "                ('CountVectorizer', CountVectorizer(analyzer='word',\n",
    "                                                    stop_words=new_stopwords,\n",
    "                                                    decode_error='ignore')),\n",
    "                ('GradientBoost', GradientBoostingClassifier(n_estimators=100, random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-11 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-11 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-11 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-11 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-11 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-11 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;TextPreprocessor&#x27;,\n",
       "                 &lt;__main__.PreprocessText object at 0x000001D455418890&gt;),\n",
       "                (&#x27;CountVectorizer&#x27;,\n",
       "                 CountVectorizer(decode_error=&#x27;ignore&#x27;,\n",
       "                                 stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;,\n",
       "                                             &#x27;our&#x27;, &#x27;ours&#x27;, &#x27;ourselves&#x27;, &#x27;you&#x27;,\n",
       "                                             &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
       "                                             &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;,\n",
       "                                             &#x27;yourself&#x27;, &#x27;yourselves&#x27;, &#x27;he&#x27;,\n",
       "                                             &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;,\n",
       "                                             &quot;she&#x27;s&quot;, &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;,\n",
       "                                             &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;, &#x27;itself&#x27;, ...])),\n",
       "                (&#x27;GradientBoost&#x27;, GradientBoostingClassifier(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;TextPreprocessor&#x27;,\n",
       "                 &lt;__main__.PreprocessText object at 0x000001D455418890&gt;),\n",
       "                (&#x27;CountVectorizer&#x27;,\n",
       "                 CountVectorizer(decode_error=&#x27;ignore&#x27;,\n",
       "                                 stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;,\n",
       "                                             &#x27;our&#x27;, &#x27;ours&#x27;, &#x27;ourselves&#x27;, &#x27;you&#x27;,\n",
       "                                             &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
       "                                             &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;,\n",
       "                                             &#x27;yourself&#x27;, &#x27;yourselves&#x27;, &#x27;he&#x27;,\n",
       "                                             &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;,\n",
       "                                             &quot;she&#x27;s&quot;, &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;,\n",
       "                                             &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;, &#x27;itself&#x27;, ...])),\n",
       "                (&#x27;GradientBoost&#x27;, GradientBoostingClassifier(random_state=42))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">PreprocessText</label><div class=\"sk-toggleable__content fitted\"><pre>&lt;__main__.PreprocessText object at 0x000001D455418890&gt;</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer(decode_error=&#x27;ignore&#x27;,\n",
       "                stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
       "                            &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
       "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
       "                            &#x27;itself&#x27;, ...])</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;GradientBoostingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingClassifier(random_state=42)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('TextPreprocessor',\n",
       "                 <__main__.PreprocessText object at 0x000001D455418890>),\n",
       "                ('CountVectorizer',\n",
       "                 CountVectorizer(decode_error='ignore',\n",
       "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
       "                ('GradientBoost', GradientBoostingClassifier(random_state=42))])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline \n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the pipeline to see if it works\n",
    "def evaluate_pipe(pipe, X_train, X_test):\n",
    "    y_preds_train = pipe.predict(X_train)\n",
    "    y_preds_test = pipe.predict(X_test)\n",
    "\n",
    "    print('Training Accuracy:', accuracy_score(y_train, y_preds_train))\n",
    "    print('Testing Accuracy:', accuracy_score(y_test, y_preds_test))\n",
    "    print('\\n---------------\\n')\n",
    "    print('Training F1:', f1_score(y_train, y_preds_train, average='weighted'))\n",
    "    print('Testing F1:', f1_score(y_test, y_preds_test, average='weighted'))\n",
    "    print('\\n---------------\\n')\n",
    "    print(classification_report(y_test, y_preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Japan'], dtype=object)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test to see whether the pipeline works \n",
    "pipe.predict(['castle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the pipeline\n",
    "evaluate_pipe(pipe, X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('destination_pipeline.pkl', 'wb') as file:\n",
    "    pickle.dump(pipe, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\rosew\\anaconda3\\envs\\myenv\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\rosew\\anaconda3\\envs\\myenv\\lib\\site-packages (from flask) (3.0.6)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\rosew\\anaconda3\\envs\\myenv\\lib\\site-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\rosew\\anaconda3\\envs\\myenv\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\rosew\\anaconda3\\envs\\myenv\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\rosew\\anaconda3\\envs\\myenv\\lib\\site-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rosew\\anaconda3\\envs\\myenv\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rosew\\anaconda3\\envs\\myenv\\lib\\site-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Country: United States\n",
      "\n",
      "Recommended Attractions:\n",
      "Attraction: Vizcaya Museum & Gardens\n",
      "Country: United States\n",
      "Description: If you want to see something that is 'very Miami', this is it – lush, big, over the top, a patchwork of all that a rich US businessman might want to show…\n",
      "--------------------------------------------------\n",
      "Attraction: Cadillac Mountain\n",
      "Country: United States\n",
      "Description: Don't leave the park without driving – or hiking – to the 1530ft summit of Cadillac Mountain. For panoramic views of Frenchman Bay, walk the paved 0.5…\n",
      "--------------------------------------------------\n",
      "Attraction: Bernal Heights Park\n",
      "Country: United States\n",
      "Description: The breezy, grassland slopes of 475ft Bernal Hill are decidedly non-touristy, and hiking them on a clear day offers 360-degree city views, along with rare…\n",
      "--------------------------------------------------\n",
      "Attraction: Virginia Aquarium & Marine Science Center\n",
      "Country: United States\n",
      "Description: If you want to see an aquarium done right, come here. In various habitats, you can see a great array of aquatic life, including sea turtles, river otters…\n",
      "--------------------------------------------------\n",
      "Attraction: Green-Wood Cemetery\n",
      "Country: United States\n",
      "Description: If you want to enjoy a slice of scenic Brooklyn in total peace and quiet, make for Green-Wood Cemetery. This historic burial ground set on the borough’s…\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Example user query\n",
    "user_query = \"I want to go hiking and see breathtaking views\"\n",
    "\n",
    "# Step 1: Preprocess the input query\n",
    "processed_input = preprocess_text(user_query)\n",
    "\n",
    "# Step 2: Predict the country\n",
    "predicted_country = final_model.predict(vectorizer_final.transform(processed_input))[0]\n",
    "print(\"Predicted Country:\", predicted_country)\n",
    "\n",
    "# Step 3: Filter attractions by the predicted country\n",
    "filtered_data = preprocessed_df[preprocessed_df['Country'] == predicted_country]\n",
    "\n",
    "if filtered_data.empty:\n",
    "    print(\"No attractions found for the predicted country.\")\n",
    "else:\n",
    "    # Step 4: Rank Attractions by Similarity\n",
    "    vectorizer_attractions = TfidfVectorizer(stop_words='english')\n",
    "    filtered_tfidf = vectorizer_attractions.fit_transform(filtered_data['Description'])\n",
    "    query_tfidf = vectorizer_attractions.transform([user_query])\n",
    "\n",
    "    # Calculate similarity\n",
    "    similarity_scores = cosine_similarity(query_tfidf, filtered_tfidf).flatten()\n",
    "    filtered_data['Similarity'] = similarity_scores\n",
    "\n",
    "    # Step 5: Output Top Attractions\n",
    "top_attractions = filtered_data.sort_values(by='Similarity', ascending=False).head(5)\n",
    "\n",
    "print(\"\\nRecommended Attractions:\")\n",
    "for idx, row in top_attractions.iterrows():\n",
    "    print(f\"Attraction: {row['Attraction']}\")\n",
    "    print(f\"Country: {row['Country']}\")\n",
    "    print(f\"Description: {row['Description']}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
